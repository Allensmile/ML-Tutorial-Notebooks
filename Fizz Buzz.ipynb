{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fizz Buzz with Tensor Flow.\n",
    "\n",
    "This notebook to explain the [code](https://github.com/joelgrus/fizz-buzz-tensorflow/blob/master/fizz_buzz.py) from [Fizz Buzz in Tensor Flow](http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/) blog post written by __Joel Grus__  \n",
    "You should read his post first!  \n",
    "\n",
    "His [code](https://github.com/joelgrus/fizz-buzz-tensorflow/blob/master/fizz_buzz.py) try to play the Fizz Buzz game by using machine learning. \n",
    "\n",
    "This notebook is for real beginners who whant to understand the basis of TensorFlow by reading code.  \n",
    "Feedback welcome __@dh7net__\n",
    " \n",
    "## Let's start!  \n",
    "\n",
    "The [code](https://github.com/joelgrus/fizz-buzz-tensorflow/blob/master/fizz_buzz.py) contain several part:\n",
    "* Create the training set\n",
    "  * Encode the input (a number)\n",
    "  * Encode the result (fizz or buzz, none or both?)\n",
    "  * create the training set\n",
    "* Build a model\n",
    "* Train the model\n",
    "  * Create a cost function\n",
    "  * Iterate\n",
    "* Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the trainning set\n",
    "### Encode the input (a number)\n",
    "This example convert the number to a binary representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0 0 0 0 0 0 0 0 0 0]\n",
      "1 [1 0 0 0 0 0 0 0 0 0]\n",
      "2 [0 1 0 0 0 0 0 0 0 0]\n",
      "3 [1 1 0 0 0 0 0 0 0 0]\n",
      "4 [0 0 1 0 0 0 0 0 0 0]\n",
      "5 [1 0 1 0 0 0 0 0 0 0]\n",
      "6 [0 1 1 0 0 0 0 0 0 0]\n",
      "7 [1 1 1 0 0 0 0 0 0 0]\n",
      "8 [0 0 0 1 0 0 0 0 0 0]\n",
      "9 [1 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "NUM_DIGITS = 10\n",
    "\n",
    "def binary_encode(i, num_digits):\n",
    "    return np.array([i >> d & 1 for d in range(num_digits)])\n",
    "\n",
    "#Let's check if it works\n",
    "for i in range(10):\n",
    "    print i, binary_encode(i, NUM_DIGITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the result (fizz or buzz, none or both?)\n",
    "* The fizz_buzz function calculate what the output should be, an encoded it to a 4 dimention vector.  \n",
    "* The fizz_buzz function take a number and a prediction, and output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [1 0 0 0]\n",
      "2 [1 0 0 0]\n",
      "3 [0 1 0 0]\n",
      "4 [1 0 0 0]\n",
      "5 [0 0 1 0]\n",
      "6 [0 1 0 0]\n",
      "7 [1 0 0 0]\n",
      "8 [1 0 0 0]\n",
      "9 [0 1 0 0]\n",
      "10 [0 0 1 0]\n",
      "11 [1 0 0 0]\n",
      "12 [0 1 0 0]\n",
      "13 [1 0 0 0]\n",
      "14 [1 0 0 0]\n",
      "15 [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "def fizz_buzz_encode(i):\n",
    "    if   i % 15 == 0: return np.array([0, 0, 0, 1])\n",
    "    elif i % 5  == 0: return np.array([0, 0, 1, 0])\n",
    "    elif i % 3  == 0: return np.array([0, 1, 0, 0])\n",
    "    else:             return np.array([1, 0, 0, 0])\n",
    "    \n",
    "def fizz_buzz(i, prediction):\n",
    "    return [str(i), \"fizz\", \"buzz\", \"fizzbuzz\"][prediction]\n",
    "    \n",
    "# let'see how the encoding works\n",
    "for i in range(1, 16):\n",
    "    print i, fizz_buzz_encode(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 1\n",
      "2 0 2\n",
      "3 1 fizz\n",
      "4 0 4\n",
      "5 2 buzz\n",
      "6 1 fizz\n",
      "7 0 7\n",
      "8 0 8\n",
      "9 1 fizz\n",
      "10 2 buzz\n",
      "11 0 11\n",
      "12 1 fizz\n",
      "13 0 13\n",
      "14 0 14\n",
      "15 3 fizzbuzz\n"
     ]
    }
   ],
   "source": [
    "# and the decoding\n",
    "for i in range(1, 16):\n",
    "    fizz_or_buzz_number = np.argmax(fizz_buzz_encode(i))\n",
    "    print i, fizz_or_buzz_number, fizz_buzz(i, fizz_or_buzz_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the set: 1024\n",
      "First 15 values:\n",
      "101 [0 1 0 1 0 0 1 1 0 0] [1 0 0 0]\n",
      "102 [1 1 0 1 0 0 1 1 0 0] [1 0 0 0]\n",
      "103 [0 0 1 1 0 0 1 1 0 0] [0 1 0 0]\n",
      "104 [1 0 1 1 0 0 1 1 0 0] [0 0 1 0]\n",
      "105 [0 1 1 1 0 0 1 1 0 0] [1 0 0 0]\n",
      "106 [1 1 1 1 0 0 1 1 0 0] [0 1 0 0]\n",
      "107 [0 0 0 0 1 0 1 1 0 0] [1 0 0 0]\n",
      "108 [1 0 0 0 1 0 1 1 0 0] [1 0 0 0]\n",
      "109 [0 1 0 0 1 0 1 1 0 0] [0 0 0 1]\n",
      "110 [1 1 0 0 1 0 1 1 0 0] [1 0 0 0]\n",
      "111 [0 0 1 0 1 0 1 1 0 0] [1 0 0 0]\n",
      "112 [1 0 1 0 1 0 1 1 0 0] [0 1 0 0]\n",
      "113 [0 1 1 0 1 0 1 1 0 0] [1 0 0 0]\n",
      "114 [1 1 1 0 1 0 1 1 0 0] [0 0 1 0]\n",
      "115 [0 0 0 1 1 0 1 1 0 0] [0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "training_size = 2 ** NUM_DIGITS\n",
    "print \"Size of the set:\", training_size\n",
    "trX = np.array([binary_encode(i, NUM_DIGITS) for i in range(101, training_size)])\n",
    "trY = np.array([fizz_buzz_encode(i)          for i in range(101, training_size)])\n",
    "\n",
    "print \"First 15 values:\"\n",
    "for i in range(101, 116):\n",
    "    print i, trX[i], trY[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the model\n",
    "\n",
    "The model is made of:\n",
    "* one hidden layer that contains 100 neurons\n",
    "* one output layer  \n",
    "\n",
    "The input is fully connected to the hidden layer and a relu function is applyed  \n",
    "The relu function is a [rectifier](https://en.wikipedia.org/wiki/Rectifier_%28neural_networks%29) that just output zero if the input is negative.\n",
    "\n",
    "First we'll define an helper function to initialise parameters with randoms values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__X__ is the input  \n",
    "__Y__ is the output  \n",
    "__w_h__ are the parameters between the input and the hidden layer  \n",
    "__w_o__ are the parameters between the hidden layer and the output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_HIDDEN = 100 #Number of neuron in the hidden layer\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, NUM_DIGITS])\n",
    "Y = tf.placeholder(\"float\", [None, 4])\n",
    "\n",
    "w_h = init_weights([NUM_DIGITS, NUM_HIDDEN])\n",
    "w_o = init_weights([NUM_HIDDEN, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the model we apply the __w_h__ parameters to the input,  \n",
    "and then we aply the relu function to calculate the value of the hidden layer.\n",
    "  \n",
    "The __w_o__ coeefient are used to calculate the output layer. No rectification is applyed  \n",
    "__py_x__ is the predicted value for a given input represented as a vector (dimention 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, w_h, w_o):\n",
    "    h = tf.nn.relu(tf.matmul(X, w_h))\n",
    "    return tf.matmul(h, w_o)\n",
    "\n",
    "py_x = model(X, w_h, w_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "## Create the cost function\n",
    "The cost function measure how bad the model is.  \n",
    "It is the distance between the prediction (py_x) and the reality (Y).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(py_x, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __softmax_cross_entropy_with_logits(py_x, Y)__ measure the distance between py_x and Y. [SoftMax](https://en.wikipedia.org/wiki/Softmax_function) is the classical way to measure the distance between a predicted result and the actual result in a cost function.  \n",
    "* __reduce_mean__ calculate the mean of a tensor. In this case the mean of the distance for the whole training set\n",
    "\n",
    "## Train the model\n",
    "Training a model in TensorFlow is extremly simple, you just define a trainer operator!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operator will minimize the cost using the [Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent) witch is the most common optimizer to find parameters than will minimise the cost.\n",
    "\n",
    "We'll also define a prediction operator that will be able to output a prediction.\n",
    "* 0 means no fizz no buzz\n",
    "* 1 means fizz\n",
    "* 2 means buzz\n",
    "* 3 means fizzbuzz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_op = tf.argmax(py_x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate until the model is good enough\n",
    "\n",
    "One epoch consists of one full training cycle on the training set.\n",
    "Once every sample in the set is seen, you start again - marking the beginning of the 2nd epoch. [source](http://stackoverflow.com/questions/31155388/meaning-of-an-epoch-in-neural-networks-training)  \n",
    "\n",
    "The training set is randomly permuted between each epoch.\n",
    "\n",
    "The learning is not done on the full set at once.  \n",
    "Instead the learning set is divided in small batch and the learning is done for each of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here an example of index used for one epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch starting at 0\n",
      "[417 122 664 322 289 778 679 654 550 363 489 172  24 795 105 333 700 198\n",
      " 404 339 471 402 240 859 907 666 495 661 153 296  23  77 423  61 603   9\n",
      " 895 254 434 642 807 594 624 248 596 611  35 315 532 866 862 231 705 108\n",
      " 204 908 499 552 408 657 651 405 525 734 130 228  53 569 593 391 653 464\n",
      " 803 415 632  62 837 458 775  85 148 452 620 367 628 892 576 675 825  73\n",
      " 758 441 200 512 529 393 640 138 112  47 717 890 432 854 896 119 521 430\n",
      " 874 416 708 650 167 707  94 149 390 765 462 541 201 210 217 223 488  44\n",
      " 286  58]\n",
      "Batch starting at 128\n",
      "[718  36 401 291 680 782 145 886 508 898 563 481 351 400 539 757 513 809\n",
      " 540  92 213 706 451 163 534 601 371 186  68 909  93 362 728 482 698 337\n",
      " 438 900  45 828 143 395 602 487 365 236  66 466 287 715 811 799 299 480\n",
      " 591 251 668 135 867 460 870 492 134 192 566 743 822 597 577 440 600 791\n",
      " 738 326  67 733 607 334 370 789 629 102 776   2 677 701 683  83 899 814\n",
      " 414 695 835 188 104 522 604 469 574 730 283 781 769 794 465 109 903  65\n",
      " 411 801 338 290 741 118 638 273 181 302 581 721 536 468 303 344 332 484\n",
      " 245 265]\n",
      "Batch starting at 256\n",
      "[ 97 505 307  90 472 843 136 726 146 547 241 709 735 687 323 369 524 846\n",
      " 678  88 151 711 125 229 314 788  59 819 357 572 724 792 450 313 324 686\n",
      " 437 796 614 630  54  79 821 779 384 635 221 787 647 378 644 166 479 179\n",
      " 546 353 444 266  72 320 203 209 714 684 838 412 298 463 761 260 573 582\n",
      " 257 249 641 562  11 375 270  84 847 117 304 774 195 531 199 387 158 818\n",
      " 114 920 162 381 356 606 259 335 912 377 627 282 191  76  60 301 518 128\n",
      " 316  37 740 374 622 349 455 592  21 100 857 623 855 749 493  46 475 202\n",
      " 906 501]\n",
      "Batch starting at 384\n",
      "[823 528 634 771  16  71 720 295 588 831 461 427 261 780 808 889 609 506\n",
      " 618 154 567 615 570 824 691 820  29 159 293 551 311 643  99 507 403 883\n",
      " 503 856 425 802 568   6 913 610 810 246 915 269 113 851 688  40 225 659\n",
      " 860 277 214 748 319 490 584 234 565 230 674 509  64 914 876 272   5 511\n",
      " 354 858 504 330 187 599 278 267 665 439 616 553 813 878 137  18 587 312\n",
      " 621 554 523   7 537 772 388 797 285 682  91 790 555 853 916 182 237 545\n",
      " 699  13 459 215  15 474  98   1 731 871 258 454 389 861 347 494 219 756\n",
      " 350  81]\n",
      "Batch starting at 512\n",
      "[737 238 232 255 864 905 276 716 396 739  20 613 893  51 713 111 120 842\n",
      " 428  86 655 839 904 564 280 306 736 147 331  32 308 189 150 190 227 300\n",
      " 784 921 798 346 770 325 514 161 262 127  38 881  63 631 141 252 762 844\n",
      " 559 359 342 443 732 722 806  39 841 271 502 168 873 755 208 800 264 413\n",
      " 885 394 827 729 542 918 773 619 543 380 561 115 702 183 829 321 583  56\n",
      " 279 180 341 431 343  55 207 764 133 783 205 719 498 284 470 826 863 447\n",
      " 693 419 845 317   4 392 305 767 176 101 517 446 226 406 672 852  57 919\n",
      " 608 598]\n",
      "Batch starting at 640\n",
      "[123 491 329 667 681 422  12 865 379 426 435  78 636 696  22 578 637 256\n",
      " 177 744 922 164   8  87  89 694 420 250 473 515 193 222 697 887 612 328\n",
      " 456 585 558 382 777 785 424 723 268 727 891 442 467 617 595 410 690  25\n",
      " 297  14  17 361 368 399 373 385 646 364 185 793 834 310 519 160 496  42\n",
      " 850 383 662 575 107 888  52 712 318 648 548 884  30 786  48 156 516 768\n",
      " 660 242 911 397 358 376 340 235 658 483 309 549 882 449 703 103  74 211\n",
      " 747 586 671  69 902 429 910 804 348 742 901 233 704 247  50 544 605 142\n",
      "  33 327]\n",
      "Batch starting at 768\n",
      "[212 830 216 751   0 144 633 366 833 418 917 849 140 486 880  80 692  75\n",
      " 639 131 178 124 579 590 877 110 759 589  95 875  10 485 372 526 894 763\n",
      " 560 184 218 836  27 448 663 132 710 152 868 497 126   3 165 294 157 139\n",
      " 848 872  49 530 673 121 355 288 174 407 535 170 816  34 453 155 753  41\n",
      " 457 626  43 897 253 220 433 538  82 752 436 274 805 760 175 685 676 500\n",
      " 476 244 409 527 817 840 652  19 556 869 533 670 520 239 173 129 243 725\n",
      " 386 689 197  28  26  96 812 510 292 360 224 171 106 746 571 336 766 169\n",
      " 478 649]\n",
      "Batch starting at 896\n",
      "[345 116 398 281 263 206 477 196 352 656 754 625 745 669 879 445 275 421\n",
      " 750 832  31 580 815 194 557 645  70]\n"
     ]
    }
   ],
   "source": [
    "#random permutation of the index will be used during the training for each epoch\n",
    "permutation_index = np.random.permutation(range(len(trX)))\n",
    "for start in range(0, len(trX), BATCH_SIZE):\n",
    "        end = start + BATCH_SIZE\n",
    "        print \"Batch starting at\", start\n",
    "        print permutation_index[start:end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.5297941495124594)\n",
      "(100, 0.53412784398699886)\n",
      "(200, 0.53412784398699886)\n",
      "(300, 0.53412784398699886)\n",
      "(400, 0.53412784398699886)\n",
      "(500, 0.53412784398699886)\n",
      "(600, 0.53412784398699886)\n",
      "(700, 0.53846153846153844)\n",
      "(800, 0.53954496208017333)\n",
      "(900, 0.54929577464788737)\n",
      "(1000, 0.55254604550379194)\n",
      "(1100, 0.55579631635969662)\n",
      "(1200, 0.56338028169014087)\n",
      "(1300, 0.59046587215601298)\n",
      "(1400, 0.61971830985915488)\n",
      "(1500, 0.64138678223185264)\n",
      "(1600, 0.6619718309859155)\n",
      "(1700, 0.6912242686890574)\n",
      "(1800, 0.72156013001083419)\n",
      "(1900, 0.71722643553629473)\n",
      "(2000, 0.78439869989165767)\n",
      "(2100, 0.83748645720476711)\n",
      "(2200, 0.84507042253521125)\n",
      "(2300, 0.83423618634886243)\n",
      "(2400, 0.90357529794149516)\n",
      "(2500, 0.90465872156013005)\n",
      "(2600, 0.90465872156013005)\n",
      "(2700, 0.9263271939328277)\n",
      "(2800, 0.93824485373781152)\n",
      "(2900, 0.93282773564463706)\n",
      "(3000, 0.94907908992416035)\n",
      "(3100, 0.94366197183098588)\n",
      "(3200, 0.93824485373781152)\n",
      "(3300, 0.96424702058504874)\n",
      "(3400, 0.96099674972914406)\n",
      "(3500, 0.9707475622968581)\n",
      "(3600, 0.94474539544962077)\n",
      "(3700, 0.97616468039003246)\n",
      "(3800, 0.95882990249187428)\n",
      "(3900, 0.97724810400866735)\n",
      "(4000, 0.97508125677139756)\n",
      "(4100, 0.98374864572047671)\n",
      "(4200, 0.98158179848320692)\n",
      "(4300, 0.99133261105092096)\n",
      "(4400, 0.97616468039003246)\n",
      "(4500, 0.971830985915493)\n",
      "(4600, 0.9848320693391116)\n",
      "(4700, 0.99241603466955575)\n",
      "(4800, 0.99349945828819064)\n",
      "(4900, 0.99674972914409532)\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "tf.initialize_all_variables().run(session=sess)\n",
    "\n",
    "for epoch in range(5000):\n",
    "    # Shuffle the data before each training iteration.\n",
    "    p = np.random.permutation(range(len(trX)))\n",
    "    trX, trY = trX[p], trY[p]\n",
    "\n",
    "    # Train in batches of 128 inputs.\n",
    "    for start in range(0, len(trX), BATCH_SIZE):\n",
    "        end = start + BATCH_SIZE\n",
    "        sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "\n",
    "    # And print the current accuracy on the training data.\n",
    "    if (epoch%100==0):  # each 100 epoch, to not overflow the jupyter log\n",
    "        # np.mean(A==B) return a number between 0 and 1. (true_count/total_count)\n",
    "        print(epoch, np.mean(np.argmax(trY, axis=1) ==\n",
    "                         sess.run(predict_op, feed_dict={X: trX, Y: trY})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '2' 'fizz' '4' '5' '6' '7' '8' 'fizz' '10' '11' 'fizz' '13' '14'\n",
      " 'fizzbuzz' '16' '17' 'fizz' '19' 'buzz' 'fizz' '22' '23' 'fizz' 'fizz'\n",
      " '26' 'fizz' '28' '29' 'fizzbuzz' '31' '32' 'fizz' '34' '35' '36' '37' '38'\n",
      " '39' '40' '41' '42' '43' '44' 'fizzbuzz' '46' '47' 'fizz' '49' '50' 'fizz'\n",
      " '52' 'fizz' '54' 'fizz' '56' 'fizz' '58' '59' 'fizzbuzz' '61' '62' 'fizz'\n",
      " '64' 'buzz' 'fizz' '67' '68' 'fizz' 'buzz' '71' '72' '73' '74' 'fizzbuzz'\n",
      " '76' '77' 'fizz' '79' '80' 'fizz' '82' 'fizz' 'fizz' 'buzz' '86' 'fizz'\n",
      " '88' '89' 'fizzbuzz' '91' '92' 'fizz' '94' 'buzz' '96' '97' 'buzz' '99'\n",
      " 'buzz']\n"
     ]
    }
   ],
   "source": [
    "# And now for some fizz buzz\n",
    "numbers = np.arange(1, 101)\n",
    "teX = np.transpose(binary_encode(numbers, NUM_DIGITS))\n",
    "teY = sess.run(predict_op, feed_dict={X: teX})\n",
    "\n",
    "output = np.vectorize(fizz_buzz)(numbers, teY)\n",
    "print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close() # don't forget to close the session if you don't use it anymore. Or use the *with* statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.81\n",
      "1        1        1 True\n",
      "2        2        2 True\n",
      "3     fizz     fizz True\n",
      "4        4        4 True\n",
      "5     buzz        5 False\n",
      "6     fizz        6 False\n",
      "7        7        7 True\n",
      "8        8        8 True\n",
      "9     fizz     fizz True\n",
      "10     buzz       10 False\n",
      "11       11       11 True\n",
      "12     fizz     fizz True\n",
      "13       13       13 True\n",
      "14       14       14 True\n",
      "15 fizzbuzz fizzbuzz True\n",
      "16       16       16 True\n",
      "17       17       17 True\n",
      "18     fizz     fizz True\n",
      "19       19       19 True\n",
      "20     buzz     buzz True\n",
      "21     fizz     fizz True\n",
      "22       22       22 True\n",
      "23       23       23 True\n",
      "24     fizz     fizz True\n",
      "25     buzz     fizz False\n",
      "26       26       26 True\n",
      "27     fizz     fizz True\n",
      "28       28       28 True\n",
      "29       29       29 True\n",
      "30 fizzbuzz fizzbuzz True\n",
      "31       31       31 True\n",
      "32       32       32 True\n",
      "33     fizz     fizz True\n",
      "34       34       34 True\n",
      "35     buzz       35 False\n",
      "36     fizz       36 False\n",
      "37       37       37 True\n",
      "38       38       38 True\n",
      "39     fizz       39 False\n",
      "40     buzz       40 False\n",
      "41       41       41 True\n",
      "42     fizz       42 False\n",
      "43       43       43 True\n",
      "44       44       44 True\n",
      "45 fizzbuzz fizzbuzz True\n",
      "46       46       46 True\n",
      "47       47       47 True\n",
      "48     fizz     fizz True\n",
      "49       49       49 True\n",
      "50     buzz       50 False\n",
      "51     fizz     fizz True\n",
      "52       52       52 True\n",
      "53       53     fizz False\n",
      "54     fizz       54 False\n",
      "55     buzz     fizz False\n",
      "56       56       56 True\n",
      "57     fizz     fizz True\n",
      "58       58       58 True\n",
      "59       59       59 True\n",
      "60 fizzbuzz fizzbuzz True\n",
      "61       61       61 True\n",
      "62       62       62 True\n",
      "63     fizz     fizz True\n",
      "64       64       64 True\n",
      "65     buzz     buzz True\n",
      "66     fizz     fizz True\n",
      "67       67       67 True\n",
      "68       68       68 True\n",
      "69     fizz     fizz True\n",
      "70     buzz     buzz True\n",
      "71       71       71 True\n",
      "72     fizz       72 False\n",
      "73       73       73 True\n",
      "74       74       74 True\n",
      "75 fizzbuzz fizzbuzz True\n",
      "76       76       76 True\n",
      "77       77       77 True\n",
      "78     fizz     fizz True\n",
      "79       79       79 True\n",
      "80     buzz       80 False\n",
      "81     fizz     fizz True\n",
      "82       82       82 True\n",
      "83       83     fizz False\n",
      "84     fizz     fizz True\n",
      "85     buzz     buzz True\n",
      "86       86       86 True\n",
      "87     fizz     fizz True\n",
      "88       88       88 True\n",
      "89       89       89 True\n",
      "90 fizzbuzz fizzbuzz True\n",
      "91       91       91 True\n",
      "92       92       92 True\n",
      "93     fizz     fizz True\n",
      "94       94       94 True\n",
      "95     buzz     buzz True\n",
      "96     fizz       96 False\n",
      "97       97       97 True\n",
      "98       98     buzz False\n",
      "99     fizz       99 False\n"
     ]
    }
   ],
   "source": [
    "# Lets check the quality\n",
    "Y = np.array([fizz_buzz_encode(i) for i in range(1,101)])\n",
    "print \"accuracy\", np.mean(np.argmax(Y, axis=1) == teY)\n",
    "\n",
    "for i in range(1,100):\n",
    "    actual = fizz_buzz(i, np.argmax(fizz_buzz_encode(i)))\n",
    "    predicted = output[i-1]\n",
    "    ok = True\n",
    "    if actual <> predicted: ok = False\n",
    "    print i, \"{:>8}\".format(actual), \"{:>8}\".format(predicted), ok"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
