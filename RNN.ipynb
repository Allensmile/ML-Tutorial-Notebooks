{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal character-level Vanilla RNN model.\n",
    "\n",
    "RNN stand for \"Recurent Neural Network\".  \n",
    "To understand why RNN are so hot you _must_ read [this](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)!  \n",
    "\n",
    "This notebook to explain the _[Minimal character-level Vanilla RNN model](https://gist.github.com/karpathy/d4dee566867f8291f086)_ written by __Andrej Karpathy__  \n",
    "This code create a RNN to generate a text, char after char, by learning char after char from a textfile.\n",
    "\n",
    "I love this _character-level Vanilla RNN_ code because it doesn't use any library except numpy.\n",
    "All the NN magic in 112 lines of code, no need to understand any dependency. Everything is there! I'll try to explain in detail every line of it. Disclamer: I still need to use some external links for reference.  \n",
    "\n",
    "This notebook is for real beginners who whant to understand RNN concept by reading code.  \n",
    "Feedback welcome __@dh7net__\n",
    " \n",
    "## Let's start!  \n",
    "Let's see the original code and the results for the first 1000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 119163 characters, 61 unique.\n",
      "----\n",
      " ,JLBhcuSwFdHYCU!i?mFSePjkl)v(t!M.ldrDV-OqSAWx:iBocJGHUUlw b.E i-gtiHnTOabv omHfcmAMw'(i:uo\"iQY!.\"um'GA!W jYANMydLbbu!.a'MUHzxnsJDiAzULI,U!pWT)vaYCQwPx:;ulgoPqGD\n",
      "mJxivk'alh,LiSJxDgS;r.yGeJnfCmDkD,EWQio \n",
      "----\n",
      "iter 0, loss: 102.771854\n",
      "----\n",
      " O hA  ieeaicmauytaas ovtf seGwayt as,ulf aot'batLbuc L idhassbac dbseoat aic  fp losnhegw ,PcdUcnna co-tW o  oAcMm\n",
      "t  uyn ao bug dDsmhatqoAtliaseeap'ha.; ec desn eee ss,!ucttoc(a,c aoeelacnorn h.oSblo \n",
      "----\n",
      "iter 100, loss: 102.940407\n",
      "----\n",
      " ln h wsa a\n",
      "afe vdbee bh tfveioyoloeeltsaliaWrlkadylclnruhpead wa \n",
      "i-ditx oab wts\n",
      "  em.lsoesu t\" H d  rsa wst wdteaidthss tsdlushl vinceG)eaeOz eops hieoesf\n",
      "t ei WiaHb-e\n",
      "n-slrwsh\n",
      "sdroe,wedpn neresl rhg \n",
      "----\n",
      "iter 200, loss: 101.077410\n",
      "----\n",
      " Gned -nd  wt wftiwp so LardpfenWimeooWpd\n",
      "u ieacetH   oponebpGa rgo\"femnkoha,\n",
      "\"ie efngnkd fhoie gt eoteh Glt.vQOtueT sl tl  n.hiipge itth e islmktw ow g rhet hauoqun cwkblo rslpuCf shas cTgtoce.l,ts fe \n",
      "----\n",
      "iter 300, loss: 99.188995\n",
      "----\n",
      "  mpnoftoefre wn fcrsrdoi dn,ldoilyn haOyttle l rrc  ownnitiiedr ihrm e bnnamsanehioeeli s\n",
      " tuhue veB aodAnopu onlcrfcwetuojdys eim ntautaar hann,letesa   ampc  esi fiaedsaelw ashi ur,otll\n",
      "Aseeinntpuwe \n",
      "----\n",
      "iter 400, loss: 97.071554\n",
      "----\n",
      " d dyoeY anip\n",
      "hwgihefhow mwiVefcwe I fe\n",
      "nrollaaiticn\n",
      " ptlahwteasenm ie'Apeftp athabloe iwH ,nn de  A  ktwtthdhel d ka flfoo sosoie alreilemFtowurlatt  na nv c?nl slleo l btanmoBto\n",
      "l\"c,gc le bIechmdim,e \n",
      "----\n",
      "iter 500, loss: 95.014480\n",
      "----\n",
      " ewplos. onfeso sditginpcaepseolGr.s intin f,d ai tlcnemId tomefl e r nphe  mho u\n",
      " tbt gdoh t Ieni t evrnan ut psusbcnena ?lsiwik Gilcepfhees  Skyt nu, t edirels yep lfek  sanbshdApc,rs ieno  t  anrm\n",
      "p \n",
      "----\n",
      "iter 600, loss: 93.053803\n",
      "----\n",
      " thixl yinodheglhigedr sor  ht heersod neben  gpit  Ar nrn ham \"i d rt h mssutIhhcnnwte atrest y tvsow un, add atinodevor\n",
      "v telrwengis ahbth\n",
      "W.god enes ren dncrn cari fis mot Yo lfod tkBithu.diny resho \n",
      "----\n",
      "iter 700, loss: 91.329670\n",
      "----\n",
      " agn\n",
      " nliaedito f se ithiri Gathhhn rl? waffemn Gnuted  o\"g wouroln\n",
      "e.f mono  lha s ocf  pio s  Hm tere it weenvon wop d \"irelnn siShed Ite matOas Caukt de medn  ,d ss cp s pebotr th\n",
      "c trfentoraeccsa p \n",
      "----\n",
      "iter 800, loss: 89.594637\n",
      "----\n",
      " n w \"Ficotalslothr lure l te m le r\n",
      ". .dar;s mthlee va d, teal ,om coohehluny megeobinhitivy uodenalluterl eou nOw k:e th  hlrekgiwels ssa\n",
      "the nIb se  k aisdS  \"elo. n;cteNren, t dyrwiuu to'nllAy doyr \n",
      "----\n",
      "iter 900, loss: 87.895688\n",
      "----\n",
      " l hetimerwddrn h k thir y b fohfre h ith!yse th th fithedm sg , ttho niusn ay?hut uanved taachitl en rire on \n",
      "jhe n bl adanrt DAght en eodeuf. s nuoat rsihoy tarthe mhlen uasitel hl  crdocthe thcef oa \n",
      "----\n",
      "iter 1000, loss: 86.080407\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Minimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)\n",
    "BSD License\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "# data I/O\n",
    "data = open('methamorphosis.txt', 'r').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print 'data has %d characters, %d unique.' % (data_size, vocab_size)\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "# hyperparameters\n",
    "hidden_size = 100 # size of hidden layer of neurons\n",
    "seq_length = 25 # number of steps to unroll the RNN for\n",
    "learning_rate = 1e-1\n",
    "\n",
    "# model parameters\n",
    "Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
    "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "by = np.zeros((vocab_size, 1)) # output bias\n",
    "\n",
    "def lossFun(inputs, targets, hprev):\n",
    "  \"\"\"\n",
    "  inputs,targets are both list of integers.\n",
    "  hprev is Hx1 array of initial hidden state\n",
    "  returns the loss, gradients on model parameters, and last hidden state\n",
    "  \"\"\"\n",
    "  xs, hs, ys, ps = {}, {}, {}, {}\n",
    "  hs[-1] = np.copy(hprev)\n",
    "  loss = 0\n",
    "  # forward pass\n",
    "  for t in xrange(len(inputs)):\n",
    "    xs[t] = np.zeros((vocab_size,1)) # encode in 1-of-k representation\n",
    "    xs[t][inputs[t]] = 1\n",
    "    hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
    "    ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "    ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars\n",
    "    loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss)\n",
    "  # backward pass: compute gradients going backwards\n",
    "  dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "  dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "  dhnext = np.zeros_like(hs[0])\n",
    "  for t in reversed(xrange(len(inputs))):\n",
    "    dy = np.copy(ps[t])\n",
    "    dy[targets[t]] -= 1 # backprop into y\n",
    "    dWhy += np.dot(dy, hs[t].T)\n",
    "    dby += dy\n",
    "    dh = np.dot(Why.T, dy) + dhnext # backprop into h\n",
    "    dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity\n",
    "    dbh += dhraw\n",
    "    dWxh += np.dot(dhraw, xs[t].T)\n",
    "    dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "    dhnext = np.dot(Whh.T, dhraw)\n",
    "  for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "    np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
    "  return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]\n",
    "\n",
    "def sample(h, seed_ix, n):\n",
    "  \"\"\" \n",
    "  sample a sequence of integers from the model \n",
    "  h is memory state, seed_ix is seed letter for first time step\n",
    "  \"\"\"\n",
    "  x = np.zeros((vocab_size, 1))\n",
    "  x[seed_ix] = 1\n",
    "  ixes = []\n",
    "  for t in xrange(n):\n",
    "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "    y = np.dot(Why, h) + by\n",
    "    p = np.exp(y) / np.sum(np.exp(y))\n",
    "    ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[ix] = 1\n",
    "    ixes.append(ix)\n",
    "  return ixes\n",
    "\n",
    "n, p = 0, 0\n",
    "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad\n",
    "smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0\n",
    "while n<=1000: # was while True: in original code\n",
    "  # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "  if p+seq_length+1 >= len(data) or n == 0: \n",
    "    hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
    "    p = 0 # go from start of data\n",
    "  inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "  targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "  # sample from the model now and then\n",
    "  if n % 100 == 0:\n",
    "    sample_ix = sample(hprev, inputs[0], 200)\n",
    "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "    print '----\\n %s \\n----' % (txt, )\n",
    "\n",
    "  # forward seq_length characters through the net and fetch gradient\n",
    "  loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, hprev)\n",
    "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "  if n % 100 == 0: print 'iter %d, loss: %f' % (n, smooth_loss) # print progress\n",
    "  \n",
    "  # perform parameter update with Adagrad\n",
    "  for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], \n",
    "                                [dWxh, dWhh, dWhy, dbh, dby], \n",
    "                                [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "    mem += dparam * dparam\n",
    "    param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "\n",
    "  p += seq_length # move data pointer\n",
    "  n += 1 # iteration counter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not a NN expert, the code is not easy to understand.  \n",
    "\n",
    "If you look to the results you can see that the code iterate 1000 time, calculate a __loss__ that decrease over time, and output some text each 100 iteration.\n",
    "The output from the first iteration looks random.  \n",
    "After 1000 iterations, the NN is able to create words that have plausible size, don't use too much caps, and can create correct small words like \"the\", \"they\", \"be\", \"to\".  \n",
    "If you let the code learn over a nigth the NN will be able to create almost correct sentences:  \n",
    "_\"with home to get there was much hadinge everything and he could that ho women this tending applear space\"_  \n",
    "This is just a simple exemple, and there is no doubt this code can do much better.\n",
    "\n",
    "## Theorie\n",
    "This code build a neural network that is able to predict one char from the previous one.  \n",
    "In this example, it learn from a text file, so he can learn words and sentence ; if you feed HTML or XML during the tranning it can produce valid HTML or XML sequences.  \n",
    "At each step it can use some results from the previous step to keep in memory what is going on.  \n",
    "For instance if the previous char are \"hello worl\" the model can guess that the next char is \"d\".\n",
    "\n",
    "This model contain parameters that are initialized randomly and the trainning phase try to find optimal values for each of them. \n",
    "During the trainning process we do a _\"gradient descent\"_:\n",
    "* We give to the model a pair of char: the input char and the target char. The target char is the char the network should guess, it is the next char in our trainning text file.\n",
    "* We calculate the probability for every possible next char according to the state of the model, using the paramters (This is the forward pass).\n",
    "* We create a distance (the loss) between the previous probabilty and the target char.\n",
    "* We calculate gradients for each of our parameters to see witch impact they have on the loss. (A fast way to calculate all gradients is called the backward pass).\n",
    "* We update all parameters in the direction that help to minimise the loss\n",
    "* We iterate until their is no more progress and print a generated sentence from times to times.\n",
    "\n",
    "# Let's dive in! \n",
    "\n",
    "## The code contains 4 parts\n",
    "* Load the trainning data\n",
    "  * encode char into vectors\n",
    "* Define the Network\n",
    "* Define a function to create sentences from the model\n",
    "* Define a loss function\n",
    "  * Forward pass\n",
    "  * Loss\n",
    "  * Backward pass\n",
    "* Train the network\n",
    "  * Feed the network\n",
    "  * Calculate gradiend and update the model parameters\n",
    "  * Output a text to see the progress of the training\n",
    " \n",
    "Let's have a closer look to every line of the code.  \n",
    "__Disclaimer:__ the following code is cut and pasted from the original ones, with some adaptation to make it clearer for this notebook, like adding some _print_.\n",
    "\n",
    "## Load the training data\n",
    "\n",
    "The network need a big txt file as an input.\n",
    "\n",
    "The content of the file will be used to train the network.\n",
    "\n",
    "For this example, I used Methamorphosis from Kafka (Public Domain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"                                                                                                                                                                                           \n",
    "Minimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)                                                                                                             \n",
    "BSD License                                                                                                                                                                                   \n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "# data I/O                                                                                                                                                                                    \n",
    "data = open('methamorphosis.txt', 'r').read() # should be simple plain text file   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode/Decode char/vector\n",
    "Neural networks can only works on vectors. (a vector is an array of float)\n",
    "So we need a way to encode and decode a char as a vector.\n",
    "\n",
    "For this we count the number of unique char (*vocab_size*). It will be the size of the vector. \n",
    "The vector contain only zero exept for the position of the char wherae the value is 1.\n",
    "\n",
    "#### First we calculate *vocab_size*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 119163 characters, 61 unique.\n"
     ]
    }
   ],
   "source": [
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print 'data has %d characters, %d unique.' % (data_size, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then we create 2 dictionary to encode and decode a char to an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, '!': 1, ' ': 2, '\"': 3, \"'\": 4, ')': 5, '(': 6, '-': 7, ',': 8, '.': 9, ';': 10, ':': 11, '?': 12, 'A': 13, 'C': 14, 'B': 15, 'E': 16, 'D': 17, 'G': 18, 'F': 19, 'I': 20, 'H': 21, 'J': 22, 'M': 23, 'L': 24, 'O': 25, 'N': 26, 'Q': 27, 'P': 28, 'S': 29, 'U': 30, 'T': 31, 'W': 32, 'V': 33, 'Y': 34, 'a': 35, 'c': 36, 'b': 37, 'e': 38, 'd': 39, 'g': 40, 'f': 41, 'i': 42, 'h': 43, 'k': 44, 'j': 45, 'm': 46, 'l': 47, 'o': 48, 'n': 49, 'q': 50, 'p': 51, 's': 52, 'r': 53, 'u': 54, 't': 55, 'w': 56, 'v': 57, 'y': 58, 'x': 59, 'z': 60}\n",
      "{0: '\\n', 1: '!', 2: ' ', 3: '\"', 4: \"'\", 5: ')', 6: '(', 7: '-', 8: ',', 9: '.', 10: ';', 11: ':', 12: '?', 13: 'A', 14: 'C', 15: 'B', 16: 'E', 17: 'D', 18: 'G', 19: 'F', 20: 'I', 21: 'H', 22: 'J', 23: 'M', 24: 'L', 25: 'O', 26: 'N', 27: 'Q', 28: 'P', 29: 'S', 30: 'U', 31: 'T', 32: 'W', 33: 'V', 34: 'Y', 35: 'a', 36: 'c', 37: 'b', 38: 'e', 39: 'd', 40: 'g', 41: 'f', 42: 'i', 43: 'h', 44: 'k', 45: 'j', 46: 'm', 47: 'l', 48: 'o', 49: 'n', 50: 'q', 51: 'p', 52: 's', 53: 'r', 54: 'u', 55: 't', 56: 'w', 57: 'v', 58: 'y', 59: 'x', 60: 'z'}\n"
     ]
    }
   ],
   "source": [
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "print char_to_ix\n",
    "print ix_to_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finaly we create a vector from a char like this:\n",
    "The dictionary defined above allow us to create a vector of size 61 instead of 256.  \n",
    "Here and exemple for char 'a'  \n",
    "The vector contains only zero, except at position char_to_ix['a'] where we put a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vector_for_char_a = np.zeros((vocab_size, 1))\n",
    "vector_for_char_a[char_to_ix['a']] = 1\n",
    "#print vector_for_char_a\n",
    "print vector_for_char_a.ravel()\n",
    "\n",
    "x = range(0,len(chars))\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.bar(x, vector_for_char_a.ravel(), 0.3)\n",
    "plt.xticks(x, chars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the network\n",
    "\n",
    "The neural network is made of 3 layers:\n",
    "* an input layer\n",
    "* an hidden layer\n",
    "* an output layer\n",
    "\n",
    "All layers are fully connected to the next one: each node of a layer are conected to all nodes of the next layer.\n",
    "The hidden layer is connected to the output and to itself: the values from an iteration are used for the next one.\n",
    "\n",
    "To centralise values that matter for the training (_hyper parameters_) we also define the _sequence lenght_ and the _learning rate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hyperparameters                                                                                                                                                                             \n",
    "hidden_size = 100 # size of hidden layer of neurons                                                                                                                                           \n",
    "seq_length = 25 # number of steps to unroll the RNN for\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wxh contain 6100 parameters\n",
      "Whh contain 10000 parameters\n",
      "Why contain 6100 parameters\n",
      "bh contain 100 parameters\n",
      "by contain 61 parameters\n"
     ]
    }
   ],
   "source": [
    "# model parameters                                                                                                                                                                            \n",
    "Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
    "print 'Wxh contain', Wxh.size, 'parameters'\n",
    "Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "print 'Whh contain', Whh.size, 'parameters'\n",
    "Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output    \n",
    "print 'Why contain', Why.size, 'parameters'\n",
    "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "print 'bh contain', bh.size, 'parameters'\n",
    "by = np.zeros((vocab_size, 1)) # output bias\n",
    "print 'by contain', by.size, 'parameters'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model parameters are adjusted during the trainning.\n",
    "* _Wxh_ are parameters to connect a vector that contain one input to the hidden layer.\n",
    "* _Whh_ are parameters to connect the hidden layer to itself. This is the Key of the Rnn: Recursion is done by injecting the previous values from the output of the hidden state, to itself at the next iteration.\n",
    "* _Why_ are parameters to connect the hidden layer to the output\n",
    "* _bh_ contains the hidden bias\n",
    "* _by_ contains the output bias\n",
    "\n",
    "You'll see in the next section how theses parameters are used to create a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a sentence from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " th there pseblfily to serm havestice.\"  Gregor with and be not intwing, sisticharry morey morcting enfureathid net it with trom breather he climale would pulling staclime, hadsing, but thears't eraide \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "def sample(h, seed_ix, n):\n",
    "  \"\"\"                                                                                                                                                                                         \n",
    "  sample a sequence of integers from the model                                                                                                                                                \n",
    "  h is memory state, seed_ix is seed letter for first time step                                                                                                                               \n",
    "  \"\"\"\n",
    "  x = np.zeros((vocab_size, 1))\n",
    "  x[seed_ix] = 1\n",
    "  ixes = []\n",
    "  for t in xrange(n):\n",
    "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "    y = np.dot(Why, h) + by\n",
    "    p = np.exp(y) / np.sum(np.exp(y))\n",
    "    ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[ix] = 1\n",
    "    ixes.append(ix)\n",
    "  txt = ''.join(ix_to_char[ix] for ix in ixes)\n",
    "  print '----\\n %s \\n----' % (txt, )\n",
    "\n",
    "hprev = np.zeros((hidden_size,1)) # reset RNN memory  \n",
    "sample(hprev,char_to_ix['a'],200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss function\n",
    "The __loss__ is a key concept in all neural networks trainning. \n",
    "It is a value that describe how bag/good is our model.  \n",
    "It is always positive, the closest to zero, the better is our model.  \n",
    "(A good model is a model where the predicted output is close to the training output)\n",
    "  \n",
    "During the trainning phase we want to minimize the loss.\n",
    "\n",
    "The loss function calculate the loss but also the gradients (see backward pass):\n",
    "* It perform a forward pass: calculate the next char given a char from the trainning set.\n",
    "* It calculate the loss by comparing the predicted char to the target char. (The target char is the input following char in the tranning set)\n",
    "* It calculate the backward pass to calculate the gradients (see the backword pass paragraph) \n",
    "\n",
    "This function take as input:\n",
    "* a list of input char\n",
    "* a list of target char\n",
    "* and the previous hidden state\n",
    "\n",
    "This function output:\n",
    "* the loss\n",
    "* the gradient for each parameters between layers\n",
    "* the last hidden state\n",
    "\n",
    "Here the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lossFun(inputs, targets, hprev):\n",
    "  \"\"\"                                                                                                                                                                                         \n",
    "  inputs,targets are both list of integers.                                                                                                                                                   \n",
    "  hprev is Hx1 array of initial hidden state                                                                                                                                                  \n",
    "  returns the loss, gradients on model parameters, and last hidden state                                                                                                                      \n",
    "  \"\"\"\n",
    "  xs, hs, ys, ps = {}, {}, {}, {}\n",
    "  hs[-1] = np.copy(hprev)\n",
    "  loss = 0\n",
    "  # forward pass                                                                                                                                                                              \n",
    "  for t in xrange(len(inputs)):\n",
    "    xs[t] = np.zeros((vocab_size,1)) # encode in 1-of-k representation                                                                                                                        \n",
    "    xs[t][inputs[t]] = 1\n",
    "    hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state                                                                                                            \n",
    "    ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars                                                                                                           \n",
    "    ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars                                                                                                              \n",
    "    loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss)                                                                                                                       \n",
    "  # backward pass: compute gradients going backwards                                                                                                                                          \n",
    "  dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "  dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "  dhnext = np.zeros_like(hs[0])\n",
    "  for t in reversed(xrange(len(inputs))):\n",
    "    dy = np.copy(ps[t])\n",
    "    dy[targets[t]] -= 1 # backprop into y                                                                                                                                                     \n",
    "    dWhy += np.dot(dy, hs[t].T)\n",
    "    dby += dy\n",
    "    dh = np.dot(Why.T, dy) + dhnext # backprop into h                                                                                                                                         \n",
    "    dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity                                                                                                                     \n",
    "    dbh += dhraw\n",
    "    dWxh += np.dot(dhraw, xs[t].T)\n",
    "    dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "    dhnext = np.dot(Whh.T, dhraw)\n",
    "  for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "    np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients                                                                                                                 \n",
    "  return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass\n",
    "The forward pass use the parameters of the model (Wxh, Whh, Why, bh, by) to calculate the next char given a char from the trainning set.\n",
    "\n",
    "xs[t] is the vector that encode the char at position t\n",
    "ps[t] is the probabilities for next char\n",
    "\n",
    "```python\n",
    "hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
    "ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars\n",
    "```\n",
    "\n",
    "or is dirty pseudo code for each char\n",
    "```python\n",
    "hs = input*Wxh + last_value_of_hidden_state*Whh + bh\n",
    "ys = hs*Why + by\n",
    "ps = normalized(ys)\n",
    "```\n",
    "\n",
    "To dive into the code, we'll work on one char only (we set t=0 ; instead of the \"for each\" loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(\n",
      ")= 0.0046 \n",
      "p(!)= 0.0011  p( )= 0.0443  p(\")= 0.0006  p(')= 0.0020  p())= 0.0001  p(()= 0.0000  p(-)= 0.0001 \n",
      "p(,)= 0.0028  p(.)= 0.0010  p(;)= 0.0019  p(:)= 0.0003  p(?)= 0.0006  p(A)= 0.0000  p(C)= 0.0000 \n",
      "p(B)= 0.0000  p(E)= 0.0000  p(D)= 0.0000  p(G)= 0.0000  p(F)= 0.0000  p(I)= 0.0000  p(H)= 0.0000 \n",
      "p(J)= 0.0000  p(M)= 0.0000  p(L)= 0.0000  p(O)= 0.0000  p(N)= 0.0000  p(Q)= 0.0000  p(P)= 0.0000 \n",
      "p(S)= 0.0000  p(U)= 0.0000  p(T)= 0.0001  p(W)= 0.0000  p(V)= 0.0000  p(Y)= 0.0000  p(a)= 0.0051 \n",
      "p(c)= 0.0018  p(b)= 0.0002  p(e)= 0.0075  p(d)= 0.1185  p(g)= 0.0011  p(f)= 0.3273  p(i)= 0.0000 \n",
      "p(h)= 0.0001  p(k)= 0.0002  p(j)= 0.0002  p(m)= 0.0923  p(l)= 0.0028  p(o)= 0.0001  p(n)= 0.0222 \n",
      "p(q)= 0.0006  p(p)= 0.0051  p(s)= 0.0191  p(r)= 0.0087  p(u)= 0.0000  p(t)= 0.0127  p(w)= 0.0040 \n",
      "p(v)= 0.3057  p(y)= 0.0001  p(x)= 0.0046  p(z)= 0.0000 "
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# uncomment the print to get some details\n",
    "xs, hs, ys, ps = {}, {}, {}, {}\n",
    "hs[-1] = np.copy(hprev)\n",
    "# forward pass                                                                                                                                                                              \n",
    "t=0 # for t in xrange(len(inputs)):\n",
    "xs[t] = np.zeros((vocab_size,1)) # encode in 1-of-k representation\n",
    "xs[t][inputs[t]] = 1 \n",
    "# print xs[t]\n",
    "hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state \n",
    "ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "# print ys[t]\n",
    "ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars  \n",
    "# print ps[t].ravel()\n",
    "\n",
    "# Let's build a dict to see witch probablity is associated with witch char\n",
    "probability_per_char =  { ch:ps[t].ravel()[i] for i,ch in enumerate(chars) }\n",
    "# uncoment the next line to see the raw result\n",
    "# print probability_per_char\n",
    "\n",
    "# To print the probability in a way that is more easy to read.\n",
    "for x in range(vocab_size):\n",
    "    print 'p('+ ix_to_char[x] + \")=\", \"%.4f\" % ps[t].ravel()[x],\n",
    "    if (x%7==0):\n",
    "        print \"\"\n",
    "    else:\n",
    "        print \"\",\n",
    "\n",
    "x = range(0,len(chars))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(x, ps[t], 0.3)\n",
    "plt.xticks(x, chars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next char code is: 41\n",
      "Next char is: f\n"
     ]
    }
   ],
   "source": [
    "# We can create the next char from the above distribution\n",
    "ix = np.random.choice(range(vocab_size), p=ps[t].ravel())\n",
    "print\n",
    "print \"Next char code is:\", ix\n",
    "print \"Next char is:\", ix_to_char[ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the previous code several time. A char is generated for a given probability.\n",
    "\n",
    "### Loss\n",
    "For each char in the input the forward pass calculate the probability of the next char  \n",
    "The loss is the sum \n",
    "```python\n",
    "loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss)\n",
    "```\n",
    "\n",
    "The loss is calculate using Softmax. [more info here](https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/) and [here](https://en.wikipedia.org/wiki/Softmax_function).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next char from training (target) was number 36 witch is \"c\"\n",
      "Probability for this letter was 0.016374230879\n",
      "loss for this input&target pair is 4.11204646779\n"
     ]
    }
   ],
   "source": [
    "print 'Next char from training (target) was number', targets[t], 'witch is \"' + ix_to_char[targets[t]] + '\"'\n",
    "print 'Probability for this letter was', ps[t][targets[t],0]\n",
    "\n",
    "loss = -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss)\n",
    "print 'loss for this input&target pair is', loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Backward pass\n",
    "\n",
    "The goal of the backward pass is to calculate all gradients.  \n",
    "Gradients tell in witch direction you have to move your parameter to make a better model.\n",
    "\n",
    "The naive way to calculate all gradients would be to recalculate a loss for small variations for each parameters.\n",
    "This is possible but would be time consuming. We have more than 20k parameters.\n",
    "There is a technic to calculates all the gradients for all the parameters at once: the backdrop propagation.  \n",
    "Gradients are calculated in the oposite order of the forward pass, using simple technics.  \n",
    "\n",
    "For instance if we have:  \n",
    "\n",
    "```python\n",
    "loss = a.x + b  \n",
    "```\n",
    "If we want to minimize _loss_, we need to calculate d(loss)/dx and use it to calculate the new_x value.  \n",
    "```python\n",
    "new_x = x - d(loss)/dx * step_size\n",
    "```\n",
    "If new_loss is smaller than loss, it is a win: we succeed to find a better x input.  \n",
    "\n",
    "Lets do the math:  \n",
    "d(loss)/dx = d(a.x)/dx +d(b)/dx  \n",
    "d(loss)/dx = (d(a)/dx)*1 + a*d(x)/dx + 0  \n",
    "d(loss)/dx = 0 + a*1  \n",
    "d(loss)/dx = a  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss = 20\n",
      "new loss = 19.7\n",
      "New loss is smaller, Yeah!\n"
     ]
    }
   ],
   "source": [
    "x = 10  \n",
    "a = 3  \n",
    "b = 7\n",
    "\n",
    "loss = a+x + b\n",
    "print 'initial loss =', loss\n",
    "# dx stand for d(loss)/dx\n",
    "dx = a #Calculate dx=d(loss)/dx analytically\n",
    "step_size = 0.1\n",
    "# use dx and step size to calculate new x\n",
    "new_x = x - dx * step_size\n",
    "new_loss = a+new_x + b\n",
    "print 'new loss =',new_loss\n",
    "if (new_loss<loss): print 'New loss is smaller, Yeah!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "#### goal is to calculate gradients for the forward formula:\n",
    "```python\n",
    "hs = input*Wxh + last_value_of_hidden_state*Whh + bh  \n",
    "ys = hs*Why + by\n",
    "```\n",
    "\n",
    "This part need more work to explain the code, but __[here](http://karpathy.github.io/neuralnets/) a great source to understand this technic in detail.__\n",
    "\n",
    "```python\n",
    "# Backdrop this: ys = hs*Why + by\n",
    "dy=-1 # because the smaller the loss, the better is the model.\n",
    "dWhy = np.dot(dy, hs.T)\n",
    "dby = dy\n",
    "dh = np.dot(Why.T, dy) + dhnext # backprop into h  \n",
    "\n",
    "dhraw = (1 - hs * hs) * dh # backprop through tanh nonlinearity \n",
    "\n",
    "# Backdrop this: hs = input*Wxh + last_value_of_hidden_state*Whh + bh \n",
    "dbh += dhraw\n",
    "dWxh += np.dot(dhraw, xs.T)\n",
    "dWhh += np.dot(dhraw, hs.T)\n",
    "dhnext = np.dot(Whh.T, dhraw)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# backward pass: compute gradients going backwards                                                                                                                                          \n",
    "dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "dhnext = np.zeros_like(hs[0])\n",
    "t=0 #for t in reversed(xrange(len(inputs))):\n",
    "dy = np.copy(ps[t])\n",
    "dy[targets[t]] -= 1 # backprop into y   \n",
    "#print dy.ravel()\n",
    "dWhy += np.dot(dy, hs[t].T)\n",
    "#print dWhy.ravel()\n",
    "dby += dy\n",
    "#print dby.ravel()\n",
    "dh = np.dot(Why.T, dy) + dhnext # backprop into h                                                                                                                                         \n",
    "dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity                                                                                                                     \n",
    "dbh += dhraw\n",
    "dWxh += np.dot(dhraw, xs[t].T)\n",
    "dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "dhnext = np.dot(Whh.T, dhraw)\n",
    "for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "  np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
    "  #print dparam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training\n",
    "\n",
    "This last part of the code is the main trainning loop:\n",
    "* Feed the network with portion of the file. Size of cunck is *seq_lengh*\n",
    "* Use the loss function to:\n",
    "  * Do forward pass to calculate all parameters for the model for a given input/output pairs\n",
    "  * Do backward pass to calculate all gradiens\n",
    "* Print a sentence from a random seed using the parameters of the network\n",
    "* Update the model using the Adaptative Gradien technique Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Feed the loss function with inputs and targets\n",
    "\n",
    "We create two array of char from the data file,\n",
    "the targets one is shifted compare to the inputs one.\n",
    "\n",
    "For each char in the input array, the target array give the char that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs [25, 49, 38, 2, 46, 48, 53, 49, 42, 49, 40, 8, 2, 56, 43, 38, 49, 2, 18, 53, 38, 40, 48, 53, 2]\n",
      "targets [49, 38, 2, 46, 48, 53, 49, 42, 49, 40, 8, 2, 56, 43, 38, 49, 2, 18, 53, 38, 40, 48, 53, 2, 29]\n"
     ]
    }
   ],
   "source": [
    "p=0  \n",
    "inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "print \"inputs\", inputs\n",
    "targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "print \"targets\", targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adagrad to update the parameters\n",
    "\n",
    "The easiest technics to update the parmeters of the model is this:\n",
    "\n",
    "```python\n",
    "param += dparam * step_size\n",
    "```\n",
    "Adagrad is a more efficient technique where the step_size are getting smaller during the training.\n",
    "\n",
    "It use a memory variable that grow over time:\n",
    "```python\n",
    "mem += dparam * dparam\n",
    "```\n",
    "and use it to calculate the step_size:\n",
    "```python\n",
    "step_size = 1./np.sqrt(mem + 1e-8)\n",
    "```\n",
    "In short:\n",
    "```python\n",
    "mem += dparam * dparam\n",
    "param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update \n",
    "```\n",
    "\n",
    "### Smooth_loss\n",
    "\n",
    "Smooth_loss doesn't play any role in the training.\n",
    "It is just a low pass filtered version of the loss:\n",
    "```python\n",
    "smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "```\n",
    "\n",
    "It is a way to average the loss on over the last iterations to better track the progress\n",
    "\n",
    "\n",
    "### So finally\n",
    "Here the code of the main loop that does both trainning and generating text from times to times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 102.771859\n",
      "----\n",
      " iOaGkb;?nUkdb(wAW :,a.ztetLhS:VNBzJE'mWDtLSU(?mrh'kEtlMPInjI\n",
      "ae?oINmD'mWhpA\"nuSf? sw;)QkOJgtFyvYgUdu:Ug-bC;L'sdd;M().,xiGrxVWqwb,H(\"bDdyyICCc)aCgNHgTzrrmGutrEBW\n",
      ")m-?SgE,yPglzt))YfS,ll)Bc\":\n",
      "owsBJCqwNNB \n",
      "----\n",
      "iter 1000, loss: 84.873661\n",
      "----\n",
      "  hee hsl, Hpooep, arr gethefy c lhor bomins ;l ithed ha, olebhe tas ncuf hershe chore ef heg tmrec\n",
      "anonvm, gon tad ghe tipert apsr e.. wat the strent o. ce nn thet  hetifit, t sos, hetiu inhunrneo, wh \n",
      "----\n",
      "iter 2000, loss: 70.122666\n",
      "----\n",
      "   finulvet hooncely coolta Wwa thein t hat mout on atkar, apt nwer so hod moosey thabd. whiuc authiut camoachaky, mom -han\n",
      "tom wwosle mine too\n",
      "wous rowol. forimeid aoumt ondlif - hheg\n",
      "s of mabvaut ahi \n",
      "----\n",
      "iter 3000, loss: 62.053303\n",
      "----\n",
      " e lallen the Gicede nfar heath,\n",
      "anpet\n",
      "mite repurlraling\n",
      "cur, ent\n",
      "th des wrow fald fis sedey\n",
      "stmint ite whal Gre ccounir, ingmand an hiyis ditd ang hecy, ,ot. to fashasbe\n",
      "I ank ftane on t his Ob th ,,  \n",
      "----\n",
      "iter 4000, loss: 57.657486\n",
      "----\n",
      " ulles owaid waw hikpist alutde llesistuld oloye un picthit\n",
      "ofpelcdis kerid too\n",
      "gh thot inth Gr. ted acige woosinle k aro fak freaf hey hatic\n",
      "tasithens wit moomy.  Bat vit sir roo anfos bos ould shled\n",
      " \n",
      "----\n",
      "iter 5000, loss: 56.447184\n",
      "----\n",
      " Thturtirs, h\" hit to bros fowsprecovourdfor iut whe Develad, ther famet\n",
      "ir fo thas bisnt chabl mit a'f for. out whe beins the k\n",
      "on\n",
      "of her Grourd atr chi,e sald th  Tule, t, ciok be, bud tork, verqne\n",
      "n \n",
      "----\n",
      "iter 6000, loss: 55.264441\n",
      "----\n",
      " t\n",
      "hir to -o, te the moreretilvere wiply adeg aifreertoog ust of the lavises that untreeal'ns thet whou cere, bas onto tot o'th.\n",
      " Io sir ios hick wasled\"'t to sptell wathe\n",
      "thit mooting wad ored brof as \n",
      "----\n",
      "iter 7000, loss: 52.592921\n",
      "----\n",
      " toused wnat lit for hey q, ould's iny, the thouglwinfing lpes dut ony and his , of rut Grase lf then.  Greterastaled com, th the sumt ever the fromethternth thewent the ven\"y Groug mocto\n",
      "thiny peen on \n",
      "----\n",
      "iter 8000, loss: 51.449716\n",
      "----\n",
      " es h, to a dond gat wasly to dist hiss bxisenfule \"mow seve. \"Sacgegon to keoble cpedel ent opve comen hacmuid himcenome iw ont asled paeve not backed hely stos room womed oom of leithet wher yow be n \n",
      "----\n",
      "iter 9000, loss: 50.655520\n",
      "----\n",
      " loully sion.  urmued ilw ond gor's sable pastowcowe. \n",
      "Int wis ntars at out. \n",
      "Grsat bo andingrog to ghe extertan\n",
      "ezof thellen ver, hero saipes he noug his if;. :\", le it ald, wad\n",
      "sout out nret bacd as  \n",
      "----\n",
      "iter 10000, loss: 51.148408\n",
      "----\n",
      " le\n",
      "betor.  And co last nos buck ision to the siqulpinighin! \"\"esseroke wing\n",
      "th pamat,\n",
      "Thadrels sougha llols he crecroom soremsle hel peat mere, butn hitheld woraclae chack ont sibnt he bertrou llencem \n",
      "----\n",
      "iter 11000, loss: 50.508766\n",
      "----\n",
      " mupseat eftrwale be machefe stobid.  Nol, deed he, uveed ghat he of to gom sike of cas to wiim and ably , on with wero had arance he fored hit hit once thelk deide to exweacea\n",
      "sussiznet h aist of the\n",
      " \n",
      "----\n",
      "iter 12000, loss: 49.002135\n",
      "----\n",
      " hed\n",
      "of the ghall tove proming.  He to pood aster it betope thacs of exporewap af that and\n",
      "cough with in outhelco ind for had that had beer an.  fMle his nothe gouls w's deen no wenther\n",
      "hark wele fisci \n",
      "----\n",
      "iter 13000, loss: 48.449597\n",
      "----\n",
      " and anderren whet pull boe, ras futh him\n",
      "felcey yeadeace tod\n",
      "bagesy all had maed\n",
      "the  hat at aflentionf wameat was mothed homkiat himsy the simning to herrewimes arpien hord and fer of then, was nothi \n",
      "----\n",
      "iter 14000, loss: 48.207952\n",
      "----\n",
      " e Gregeh they she stored alr bace  aOd at chingiss\n",
      "tathund shack.  Grecore that thenes was waslling ino bameem so efadl\n",
      "ques is oumhend apenly dokd selibd\n",
      "doflore enghing hipal as inse'mclwone nonk be \n",
      "----\n",
      "iter 15000, loss: 48.907801\n",
      "----\n",
      " nd she was The nom.  Hlyen\n",
      "in was loor, seoo\n",
      "stired\n",
      "and sed, and couls alsly doim onid cas woid,, epidi\"sr. , and to ke was take for seve\n",
      "time the kid, am that he he has eaiborgong\n",
      "opinathe whimsis la \n",
      "----\n",
      "iter 16000, loss: 48.000070\n",
      "----\n",
      " e in there he at him lehruine had yound that to thelo mouth of wast all ald futume the chenf alle sarn and wad himseatif's had on'them thew wnow buld and no\n",
      "mum reen his tor'bole caid mas smyord haven \n",
      "----\n",
      "iter 17000, loss: 47.052738\n",
      "----\n",
      " ly though whewart\"y way with he tios ad to caan bo to wave bithen  Mranedse fo fisuned the purtent,; aurivire the all spree,\n",
      "here of this\n",
      "faid thit to ever this was tut a, deven whetel thew had uile w \n",
      "----\n",
      "iter 18000, loss: 46.613418\n",
      "----\n",
      " fomserte the dowtor\n",
      "he come him, thitas door ghen bae thime hed penalr, trersenter.  Thime chag, able\n",
      "seacteat sheremerong chen'l ut hinge agly forve. whan -\n",
      "qut the gooad hissen, sfed ofthart.\", evis \n",
      "----\n",
      "iter 19000, loss: 47.133525\n",
      "----\n",
      " \n",
      "bee. Seather litped shist and maked the mowing.  Jramelt ust th e, soo there tood sarwly his lonly, intad she alat stand suthe with thing hers ith\n",
      "seliig moughtr non frmed\n",
      "wad the rtellamy wMrk srond \n",
      "----\n",
      "iter 20000, loss: 48.061885\n",
      "----\n",
      " o enyenciartecllouch coul sidcing, able withen.\n",
      "him erover fom wath mole\n",
      "cerswtisizis was be whing  ood dast.  By to dordiif, sure?\" - seen here he clims sfing thes that ure\n",
      "whath fout leer was yoa so \n",
      "----\n",
      "iter 21000, loss: 46.719345\n",
      "----\n",
      " s luct wonk his cithtired\n",
      "the\n",
      "penout\n",
      "deinod park - had his for in- he\n",
      "haver, asly torbed aillurs, ceall to to\n",
      "enathat hirply of tha\n",
      "lide of so thes gishingith\n",
      "had siscede frough Yom.  The sifser as he \n",
      "----\n",
      "iter 22000, loss: 45.884816\n",
      "----\n",
      " or\n",
      "of plournew, the  him, unames, to the \n",
      "ild asly fid on intte to to not pee heat and there aof th sted his fawcowt the tiste suth.  Os, male Gregor\n",
      "flowe furloor, reat had fither.  He seonenom, apem \n",
      "----\n",
      "iter 23000, loss: 45.671542\n",
      "----\n",
      " r obe hep the wathany that seremabuitisse thoy tot sosed to aid ouking\n",
      "the otimed abin!edy it the kad toce bame tow refpesion than it hat sith aiding to seatremeresten tad\n",
      "oud sald but it top hin to w \n",
      "----\n",
      "iter 24000, loss: 46.853643\n",
      "----\n",
      " ide wint that gone to hit\n",
      "pat heve had ting the lore's tader ande, opecons nos dowprotor.  Mrow of\n",
      "to purunlyeoulk; antistonrs anled had more not in wat wotl, to lightruge wour hor, her\n",
      "suted hunan's  \n",
      "----\n",
      "iter 25000, loss: 47.061258\n",
      "----\n",
      " It himpenaling lous\n",
      "of tros mowisplwert was\n",
      "cost alled and whed and in hamas andivelf to ha fend yo\n",
      "ghe ny's if the sall, But thid, of he heps to\n",
      "on ableap could to thot lever ono\n",
      "gonk dompires null e \n",
      "----\n",
      "iter 26000, loss: 45.746991\n",
      "----\n",
      " etles at had dantictay Inded simpobewthand deild he\n",
      "feat and catle topentiffing buthen they in moruspainted the sicaithtlight lachte'nd.  He domsand\n",
      "wim leprly alcplentrigh hor\n",
      "the reeny ut get wadnit \n",
      "----\n",
      "iter 27000, loss: 45.419832\n",
      "----\n",
      " n hich him caate, the\n",
      "trematilg aly.  Buse ttine her aepay; of pueming and leing.  Hiatse, in to hit she ver furmith a\n",
      "disilester hip\n",
      "he hones Gregor to kod carefut, at thher eryas usming on wo\n",
      "rut he \n",
      "----\n",
      "iter 28000, loss: 45.144714\n",
      "----\n",
      " ed tbow yoursiinn\n",
      "wak hif to dinawintiweved his\n",
      "reen to the\n",
      "was bute negridiged refordly tloy\n",
      "warligiming ur but terelalr, furnoughthed and reat aboow he coand to his was to the dagarboning of thed th \n",
      "----\n",
      "iter 29000, loss: 46.233013\n",
      "----\n",
      " ing intas \"f am ofith to be\n",
      "hars qua dound  rack blede somelf\n",
      "his but.  He stack tuther\n",
      "to suthep gef ted vis mleel doaike ford\n",
      "not at firl, to he reenf he had withar whe conly nes mentirter refhan wi \n",
      "----\n",
      "iter 30000, loss: 46.070603\n",
      "----\n",
      " y now stortire. .\" urive stilling enod to fidale lent to werifle he corsle ith erelfing really fare to have reath yer.  Their, to Greilly seat rourd oning roor\n",
      "alke fullly wouly nof, mutred, would thi \n",
      "----\n",
      "iter 31000, loss: 44.834632\n",
      "----\n",
      " omsane was iths fory, door botind he ofill of\n",
      "would hing beer and his singly at backay they wenfure halst been thed and whele endors if foring and to would slae hes ast erely jusmett conw aghe room in \n",
      "----\n",
      "iter 32000, loss: 44.809857\n",
      "----\n",
      " was was the\n",
      "muth him no\n",
      "bentelft alr any whe call it was of\n",
      "gut way the onsiwting to donbaped and\n",
      "in her ardene way hil thowing bletbullyos onitimetint!\n",
      "him pad, would fald ers\n",
      "wim as they was gather. \n",
      "----\n",
      "iter 33000, loss: 44.672250\n",
      "----\n",
      " handin; wo k\", \"e congen gentmentors the had he cresill sa that of the room on whios go flopaly her. \n",
      "He rangaking on chat\n",
      "he thall and his\n",
      "sa firs it, babad he hand alf they hust's roord,\" and fork a \n",
      "----\n",
      "iter 34000, loss: 45.456074\n",
      "----\n",
      " ad th uchinis allage pading to! gakethin't leave anve pohs thes thouse cloul \"Gregor the choor.  And he now it hes to he.  Het everor be's for? Hous'th at himsing it rous it rosm camlicine liygon as i \n",
      "----\n",
      "iter 35000, loss: 45.000613\n",
      "----\n",
      " od\n",
      "of\n",
      "ereaar - werd eniwe reapple lond  Grona beef, fraintroding in dome.  Gregor it ontroage as door was wes veruge filly ureed he nild? bad gonthar tothen famed was to\n",
      "his faread riol make dist nide \n",
      "----\n",
      "iter 36000, loss: 44.181932\n",
      "----\n",
      " she wauch lecke a bund chenheded to her\n",
      "sapy chere comout it mot as been for the filgher of all cane have that cee\n",
      "- peat out opes him simetage weile not ort\n",
      "with\n",
      "thas and, and to repcrunt homed heatl \n",
      "----\n",
      "iter 37000, loss: 43.932254\n",
      "----\n",
      " tsen somsimoustout to dist her, leak restenter the hopey herreave samelite,\n",
      "the laf; soven Grest quitol, there comeltaighap mome in hak to had suster of\n",
      "crazed aruttain, cistreced on,\n",
      "been\n",
      "fompen henc \n",
      "----\n",
      "iter 38000, loss: 44.421262\n",
      "----\n",
      "  reay\n",
      "as\n",
      "he to seact omor torea flit thed a foul upt hind.  Id mos yor, boyd her and puldivaveway and her be reen as apleto was uncongtrem, was dr the misibreray, apdefprethen miak ard come and to hha \n",
      "----\n",
      "iter 39000, loss: 45.395142\n",
      "----\n",
      "  soygoon, a bed alr was by, shis sfuld been ly theimssed, in core.\"  I'm, distof\n",
      "he nablly to necr cong rNenly to diat that to ke him cead, every of go\n",
      "you ill hel to been seven not\n",
      "his parfatrus no g \n",
      "----\n",
      "iter 40000, loss: 44.448459\n",
      "----\n",
      " med\n",
      "it there but whowe purlige sidand to frmers go that where side hood\n",
      "to see him to to the chatt of the\n",
      "ceachout his fadibed thene fockibe he we cest to get There he arseminghing nfugh the piouscess \n",
      "----\n",
      "iter 41000, loss: 43.715473\n",
      "----\n",
      " rout at he was restald there unt what \n",
      "bather lild door beltes fverov, the vrom uidt ayeped, not for the eas; wighrreay biturn butl uidastmen she save cound not becrel heit the pack dome\n",
      "waspay, in to \n",
      "----\n",
      "iter 42000, loss: 43.480933\n",
      "----\n",
      " ick op and the lemplearas was as wherestemowo his mother alias more was ereat then the deshat.  \"\"'s alm the sable roun thay ibmeding hea dicung the ricing had they lade ar, ary\n",
      "Gr good,, theims -efin \n",
      "----\n",
      "iter 43000, loss: 44.505852\n",
      "----\n",
      " on saly\n",
      "bet? \"Ow.  I' torder, \"ees.  Gregor be non gentod he clald and alf and cist timand or a nove courr that\n",
      "to and wank out perncite, way ceacher atand sumain am woulsented; the chisted to gas it, \n",
      "----\n",
      "iter 44000, loss: 44.762261\n",
      "----\n",
      " id gettleck of the, mowhanginess or\n",
      "hour cis there hadrersolk be fling thompsars hirrinith.  Gregor whad to had sallidny wasle in., lead ond himsed\n",
      "and bet\n",
      "ho seadly pliy.  Mny cont, his heat the aid  \n",
      "----\n",
      "iter 45000, loss: 43.822472\n",
      "----\n",
      " ely this ranfien and the fand now as some bexuled then, she of irto\n",
      "houlm tor evening of cllasinckesfuld had had his sumnerainst com-spratither pvery soase sainy so had that his\n",
      "now s, and with od sal \n",
      "----\n",
      "iter 46000, loss: 43.471045\n",
      "----\n",
      " had co therether at exublebone the enxireen hered appeect, wouved out had bed ir sible waplouse though, monemeritt cor hirrirnkyo to move to sleer thares, mormatpsennoat the\n",
      "anding hit hith, at outher \n",
      "----\n",
      "iter 47000, loss: 43.292716\n",
      "----\n",
      " nting of his, Gregoud to it.  \"Gy\n",
      "hercedy Gres a frdetf out\n",
      "woser\n",
      "themstadr the sleache wanded. \n",
      "Thet weser tamutclered, areworf hey latharite,\n",
      "brimettroursien aliged ith sporing whakercessly wrom his \n",
      "----\n",
      "iter 48000, loss: 44.591429\n",
      "----\n",
      " en, the\n",
      "strong cas:\n",
      "gat yous and nout in that were\n",
      "ast the copt abouthed purrith, ho fat he wadreariceachion, pact whingeingore oulcarr Gregor's sisting's fakentone\n",
      "ha ghersenateable but pat butw be G \n",
      "----\n",
      "iter 49000, loss: 44.479155\n",
      "----\n",
      " lemstelfing.  Gregor thay though hor sef, injuon, anding evenficher, everighere to prear leall of fire the vor gote hip had\n",
      "pat tikentarte shach the she he weide and she roing by a descan to deswatoly \n",
      "----\n",
      "iter 50000, loss: 43.319191\n",
      "----\n",
      " the the rain, and howl fand a moms reither bang has hall hersetims his notiswould it.  Ontire leay, wtuld; of cricay, notlech have a hake on to she it bien fation thourneyst aided the ristale andy but \n",
      "----\n",
      "iter 51000, loss: 43.290763\n",
      "----\n",
      " t for every wele wanted clewe it to lespednanct becase \"elly agentrong in\n",
      "as cantile his falf his stactood net a comrintely as, out at ts explingarry ittinge even to Gres.  He heatiste bed into him, w \n",
      "----\n",
      "iter 52000, loss: 43.135467\n",
      "----\n",
      "  othest if ly.\n",
      "\n",
      "\"Comereving he als\n",
      "sinnsiungruther mocreding int concole srow, Gregor's beand wingone go blabreauthen of but hak even they hers that shear, was cat ast, in they yous mith that without\n",
      " \n",
      "----\n",
      "iter 53000, loss: 44.011039\n",
      "----\n",
      "  in wammike\n",
      " Mro, ne siot able the ops self aide the other, and the\n",
      "played, foudared opery w\"ime to that had ly theigher take the look thac usted quiped him, to bace\n",
      "orenuled entwat the room thelf hea \n",
      "----\n",
      "iter 54000, loss: 43.622811\n",
      "----\n",
      " oure.  He weple his did quipt hise chat wimssono thithen  upmy oto at had bea laying in thing this been, the wised of the shis was frnimelfarmen.  Gregor had the meand, sumbowas nin siled a riour his  \n",
      "----\n",
      "iter 55000, loss: 42.689613\n",
      "----\n",
      " queparen trist now lordemestast his lowny ursune\n",
      "been\n",
      "inh with the room out and sustly\n",
      "Mneteffart rowng on alr to cired thaus in her all to merelfursets therrswent shicl and ale murpery aid, the say s \n",
      "----\n",
      "iter 56000, loss: 42.712604\n",
      "----\n",
      " otile and gork fiored sowd oth werle of him precisterd tell expliped in Grence, irwthea'ster had enough tudenountwon't he\n",
      "couk\n",
      "out he bed gote.  That had rissing mob hall her and he could almstroatsly \n",
      "----\n",
      "iter 57000, loss: 43.096987\n",
      "----\n",
      " n ged and enterids dess\n",
      "been evenout on to\n",
      "time led thenivion a difray the filt ingo\n",
      "was arbiging the ltaver tum. s oveind his not rake dowrilind\n",
      "mogher, himses, shour, wotly os rapered ouft the fle n \n",
      "----\n",
      "iter 58000, loss: 43.931446\n",
      "----\n",
      " xarm the bact invawently bonit, warned an have to de serswous\n",
      "and.  \"Ho shrelf, swa\n",
      "fallthing\n",
      "fatse a and gas eved his expery moukhit, of able in kivent whet iver threen\n",
      "agethaiked had tordying as\n",
      "kef \n",
      "----\n",
      "iter 59000, loss: 43.196573\n",
      "----\n",
      " f fomet the sideded\n",
      "to havh hist sust beco rimm an it he reatusceter the furn the sisced with omse lformarte the werrying threlf he was stork formet his timeJned, was \"eall\n",
      "jumself\n",
      "ans from he could a \n",
      "----\n",
      "iter 60000, loss: 42.410234\n",
      "----\n",
      " e cours\n",
      "at Gregor of\n",
      "how in\n",
      "had whigher leally, wfury on to thewfilenands queet was Gregor shaded\n",
      "in the chanit as wher even appreation aparetmentoos brise that  For wiod sa torse tot\n",
      "ham.  He came hi \n",
      "----\n",
      "iter 61000, loss: 42.353292\n",
      "----\n",
      " owen vien a\n",
      "doom wnaned tarkne her one stion als, him his pory for't bess, sinftrivereading festroon\n",
      "Gregor's wakings; in onjeched aclayifive.  \"Yor habewing early coulced wampear been\", Gregor segete \n",
      "----\n",
      "iter 62000, loss: 43.192527\n",
      "----\n",
      " the somance't corgon\n",
      "\"food and the buct\n",
      "of thit he simpe) much exive gehe gead, any sustion a roying corgissertent song the was\n",
      "undecharesidn the t, at what it, and haver a freatcoom to mut dowfach le \n",
      "----\n",
      "iter 63000, loss: 43.605465\n",
      "----\n",
      " n how thom trom wird his vor hers be sillide\n",
      "sned goishing, he cless\n",
      "and there had out oply with he had of had that he would susst was and kited of wassing, while at lelf their convention? It not tad  \n",
      "----\n",
      "iter 64000, loss: 42.703089\n",
      "----\n",
      "  fhespleid lethel\n",
      "his\n",
      "sfar word room\n",
      "soidn a ple reegoned\n",
      "the\n",
      "waund reons he the being reaniffelw dreaking falled\n",
      "him\n",
      "ago to mufterpennister hear a leef a doith and itlyer the flas reelald now\",\n",
      "andsi \n",
      "----\n",
      "iter 65000, loss: 42.307132\n",
      "----\n",
      " even havied an him by foud uut her abouts evy ungints awer aboly his\n",
      "been he coul up aboe\n",
      "mowe buseid nowoun, tha room now to drabpenine food, out be that dont; stions but seat mous\n",
      "it ide whole up cl \n",
      "----\n",
      "iter 66000, loss: 42.252442\n",
      "----\n",
      " gon had hay sightre that she\n",
      "doughis the she to dights would beand to even hapde reother thine would nindthers, out poosly dois bufredmy\n",
      "not her in the stact on the\n",
      "prolbeaver as keell his to\n",
      "antsice, \n",
      "----\n",
      "iter 67000, loss: 43.444681\n",
      "----\n",
      " p.  At he weme heversed.\n",
      "\n",
      "Ithabered, and she enterlying tles it.  I wise tond without proble each.  Shes with fancesum, for upjor the fletres much: \"Jurilt here out it beas the lovely lork of the toin \n",
      "----\n",
      "iter 68000, loss: 43.532603\n",
      "----\n",
      " ilde liye than\n",
      "him.\n",
      "\n",
      "Breelvee slours his furing pack if the freen\n",
      "derk hander wa pust thes all then you dest hin the coul bad than eat thing, so hand that thime- to asmy fly had oning bed outh pale ke \n",
      "----\n",
      "iter 69000, loss: 42.511739\n",
      "----\n",
      " n\n",
      "had mase Gregor de sister the iny in, ththe wams hifr at lefs, the ais the restrooded out\"'s had ast Withed was had not him fane be that quicore he wast bet with int with a toled, bvealent undentrou \n",
      "----\n",
      "iter 70000, loss: 42.292701\n",
      "----\n",
      " e\"d but brease to peented\" he had sherong ring effer wo dap, to abling that, that heinfile his dakias dis room she and id onsh they beed -wan sood did sisture how shitout, of Gregor opengur, whalk, Gr \n",
      "----\n",
      "iter 71000, loss: 42.332440\n",
      "----\n",
      "  but was not dowe;\n",
      "that wen tmanterned acarotlingentmaid the of orgeustionst say when be this to his morned youst of he\n",
      "wotend ily coorce anyd as ighhaunst room it\n",
      "mote to gen now wher - to She fily r \n",
      "----\n",
      "iter 72000, loss: 43.056898\n",
      "----\n",
      " riemw out\n",
      "the rocite cle mole elf thele\n",
      "wam drar to Gregor things the keet boyglas upsed fitgons so the been from himpeew had helt his forverned timem any of was become\n",
      "wher lit whirring everyoin, and \n",
      "----\n",
      "iter 73000, loss: 42.671558\n",
      "----\n",
      " s sosh onely filid seen.\n",
      "\n",
      "She diimempnith! It\n",
      "heat, dorster would \"othever\n",
      "elvery and an\n",
      "would stapced.  Gregor. \n",
      "UNra temprough and ather, as if he ver fees meren chice prowreasibut emp asour alt; an \n",
      "----\n",
      "iter 74000, loss: 41.943240\n",
      "----\n",
      " w even bed evingow living over alpisters formared whund premet had the\n",
      "fert be o sisteat can\n",
      "alven, bove, when mughat of side the doon\n",
      "he caaked thing woveltily carrerided of the sime a sored tovequra \n",
      "----\n",
      "iter 75000, loss: 41.960831\n",
      "----\n",
      " his heave dige; ain sed to doot his\n",
      "carent\n",
      "strap had the chinded awteef mully whenry.  Grchas ustalssy elrood it's rate be\n",
      "trage streatfor the how the her wos coudlenpy thicwant nowing sode liftlecour \n",
      "----\n",
      "iter 76000, loss: 42.124438\n",
      "----\n",
      " all litta letthoust had read now?d was \"Yete\n",
      "frong nowo stall her the fathen to him.  The onteely thow she it Gre meather\n",
      "and was his shad ontins.\n",
      " Wivemed whe nack mach seathicuitury, bped ftaif the  \n",
      "----\n",
      "iter 77000, loss: 42.769596\n",
      "----\n",
      " re tunithinur as had meremanly come in that thelr at whee\n",
      "were wind he copes.  Nemore to a freatanal he wan evenegs mood e of of the oth\n",
      "almsuped react without - on thre's ins beetinnibly.  Yovemer th \n",
      "----\n",
      "iter 78000, loss: 42.181239\n",
      "----\n",
      "  the lived ore fremer, com.  Hhe lay outtousted une hingiverut for), buenssed from were he eadly with toisk of crack that Gregor heaf the had pubwought hal reratiest dove frung to could to you\n",
      "on thec \n",
      "----\n",
      "iter 79000, loss: 41.601897\n",
      "----\n",
      " ut say, a tuted handpenther even of cuad a lowly andely, the\n",
      "from him, in nown so dook and in thes, she was way\", puther\n",
      "he crajuol, nother mpact bem the ol's not it's disor been farry have made had d \n",
      "----\n",
      "iter 80000, loss: 41.544162\n",
      "----\n",
      "  apparn,, her indid for the fady now he neapso eyck by Greg time ht he htraxinsting, in pleat erhabins\n",
      "the door his foncy if his eppiss.\n",
      "\", or thep, expeceout\n",
      "even even thard toor\n",
      "on and he onot cast, \n",
      "----\n",
      "iter 81000, loss: 42.151469\n",
      "----\n",
      "  operdound thearffomen and and lether. \"But \n",
      "epeatits compare, \"roms.  \"It Paid was ur. yery ommed intiog thereven just a praate cerscicking wart:\n",
      "\"And\n",
      "they\n",
      "wastont ound,\n",
      "wasreat.  Arm, was newore, ma \n",
      "----\n",
      "iter 82000, loss: 42.878405\n",
      "----\n",
      " lamay bed gould out somered as clell inhe to enty time had speciticisifage same reying whiling.  Mage\n",
      "he hims\n",
      "coom.  Agk,\n",
      "\"Gregire, ot\n",
      "her sidt, lates if custrowike be be breevel?\n",
      "Thad\n",
      "no Mut\", persoi \n",
      "----\n",
      "iter 83000, loss: 41.986615\n",
      "----\n",
      " ters\n",
      "it.  Gregor out the ase\n",
      "she had flott unkis.  \"I was ronented, inthe\n",
      "the sing and so the beced cly\n",
      "sive her for the cery gould\n",
      "hards, roornened of\n",
      "streaturd a mowe\n",
      "letf in overy inmast enproentio \n",
      "----\n",
      "iter 84000, loss: 41.241120\n",
      "----\n",
      " , had fike sings of Gregor fored even his foplow prom, of\n",
      "dikide had un houch the of he himsebodem; nid he hall\n",
      "desself\n",
      "to shrement could way it was sistle louk as he her on he was yotay, no des for h \n",
      "----\n",
      "iter 85000, loss: 41.489131\n",
      "----\n",
      " mores ag\n",
      "his learf.  Juther tole she puikes.  It\n",
      "worenk Grete, Aat to kit murpentems hert buck undefst in then sishe hissid\n",
      "to the win\n",
      "soon's alurtelvelwto blieroon his able of hards of\n",
      "the cours, he  \n",
      "----\n",
      "iter 86000, loss: 42.668925\n",
      "----\n",
      " os\n",
      "that the dister an, lovelown bed aper cle\n",
      "and reeppeds.  By to ss?by bove of in roiching out\n",
      "fell on the\n",
      "save to by injom,\n",
      "he\n",
      "ceas\n",
      "it a sullsspanible It\n",
      "he lift, updone a ling his moths abroned we  \n",
      "----\n",
      "iter 87000, loss: 42.873488\n",
      "----\n",
      "  illuvine, all to Srow sape all enterupsh or.  Thelest of the daped eren expeatelf then leer waoned to a had room ain amayeve allly to fald prombe intont\", irtutly, bet it would sistlelurd hady into m \n",
      "----\n",
      "iter 88000, loss: 41.661146\n",
      "----\n",
      "  leen abe tunodeds mick that he stainy to thick, mecale rescall the here of at hifle was now fill con't all be to more had yortister and bent have to be that his seeding the\n",
      "lery to do ons you sentore \n",
      "----\n",
      "iter 89000, loss: 41.561881\n",
      "----\n",
      " mole, the way nothing with.\n",
      "\n",
      "inded her he pule sarss; hil other all forch? Sem in anyding. Yeule he leathis carly hit adelved fouve the biftaatly for had on rave operet out pall have had serplice, shi \n",
      "----\n",
      "iter 90000, loss: 41.619195\n",
      "----\n",
      " isting therd com.  But to cetcalo\n",
      "fle be his slock\n",
      "thatslyo to gher not now, enttssen, had reacked undous seavioutwnesing was bemed on torfummilf sumssse the chain\n",
      "thay and liod methe on the carp thin \n",
      "----\n",
      "iter 91000, loss: 42.458557\n",
      "----\n",
      "  craying he soid with the stremd and the'rresse quice the mocled in at emereabe befock the mory been conser\n",
      "dwould dill a forks go\n",
      "could nothing cterreen be whove soon's coodshen, be the tolk ha lough \n",
      "----\n",
      "iter 92000, loss: 42.160907\n",
      "----\n",
      "  he had faked its - Gregor fing had was ento hese a she\n",
      "stomed, and expan. \n",
      "\"Ix Sithouf. \"Could lid ceppostontars\n",
      "stros llad but towis lepent, and agaif\n",
      "fithing asked the chisple.  The giles morsto\n",
      "st \n",
      "----\n",
      "iter 93000, loss: 41.307235\n",
      "----\n",
      " ? Wat every by and soundt!\"\n",
      "from some for's have even bed\".\n",
      "\"Seche, sorded other the exped had lets the chenr to all that on, Gregor on cosped.  Gregor was prestliture uchions, reaseith, harde ad nead \n",
      "----\n",
      "iter 94000, loss: 41.396381\n",
      "----\n",
      " e cartraatemeve.  Bonicain, hither ancegal\n",
      "was do that whing unbeemed re? and of entispolf his moth withsrounecine way\n",
      "and\n",
      "the ditere is Gregor's ceatlyed oring gosellespent theis; to awhon than had u \n",
      "----\n",
      "iter 95000, loss: 41.388006\n",
      "----\n",
      " de ard she him with the doom thingloiss daply anking now nex daund meadly other to\n",
      "seresenther, loor that ent eachatily the alation he willowting ba the wquening im and not and beforess agaying chasie \n",
      "----\n",
      "iter 96000, loss: 42.180598\n",
      "----\n",
      " ing the get wofkard and stolchoutted wat ir\n",
      "himnaze\n",
      "or reawit would he no whom. \n",
      "Duthars on the sistrinove frocly mote\n",
      "the clerk a labody iny\n",
      "st. Shes stipred!\", wnom wampoure crolruirs, all impaped h \n",
      "----\n",
      "iter 97000, loss: 41.516028\n",
      "----\n",
      "  if the would, it\n",
      "soul the dise, studing noor would\n",
      "his inceed lugh. Samseat apped now in abode sids alress; arnbo- jushed awlall the nonediftled\n",
      "ttartited was been\n",
      "sive ute the sionetilted in wond bu \n",
      "----\n",
      "iter 98000, loss: 41.140045\n",
      "----\n",
      " the lithlily nom in the from his been moshed to\n",
      "him.\n",
      " His tork's\n",
      "noto but he at need the\n",
      "stak on go knate will nes was of the would\n",
      "rackked.  He had ferced on so there what cleay arither\n",
      "the stave foi \n",
      "----\n",
      "iter 99000, loss: 41.060023\n",
      "----\n",
      " red wald; Grese, aventer, thad his clo\n",
      "ceathing the room\n",
      "thucusly\n",
      "he time as tuch\n",
      "but hely in ghe it he showemst to jubovely even and tace, on evenyy, yigigh sone rilemed theie thentay, cly.\n",
      "\n",
      "Them\n",
      "the \n",
      "----\n",
      "iter 100000, loss: 41.516106\n",
      "----\n",
      " ced it them\n",
      "fore his soont but peicborand his manest rentabed with go to notht, in les with,t the lith a clas he evelece cerfite; even and greemaching roung now one britgon.  The makepars and to ir, w \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "n, p = 0, 0\n",
    "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad                                                                                                                \n",
    "smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0                                                                                                                        \n",
    "while n<=1000*100:\n",
    "  # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "  # check \"How to feed the loss function to see how this part works\n",
    "  if p+seq_length+1 >= len(data) or n == 0:\n",
    "    hprev = np.zeros((hidden_size,1)) # reset RNN memory                                                                                                                                      \n",
    "    p = 0 # go from start of data                                                                                                                                                             \n",
    "  inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "  targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "  # forward seq_length characters through the net and fetch gradient                                                                                                                          \n",
    "  loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, hprev)\n",
    "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "  # sample from the model now and then                                                                                                                                                        \n",
    "  if n % 1000 == 0:\n",
    "    print 'iter %d, loss: %f' % (n, smooth_loss) # print progress\n",
    "    sample(hprev, inputs[0], 200)\n",
    "\n",
    "  # perform parameter update with Adagrad                                                                                                                                                     \n",
    "  for param, dparam, mem in zip([Wxh, Whh, Why, bh, by],\n",
    "                                [dWxh, dWhh, dWhy, dbh, dby],\n",
    "                                [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "    mem += dparam * dparam\n",
    "    param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update                                                                                                                   \n",
    "\n",
    "  p += seq_length # move data pointer                                                                                                                                                         \n",
    "  n += 1 # iteration counter            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback welcome __@dh7net__!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
