{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for pictures genaration\n",
    "This notebook is an experiment. I tryed to generate a picture pixel by pixel using an RNN.  \n",
    "each pixel can be black or white. \n",
    "__WIP__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import needed for Jupiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import needed for the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import fnmatch, os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers functions\n",
    "to save a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need to be called within a session\n",
    "def write_png(tensor, name):\n",
    "    casted_to_uint8 = tf.cast(tensor, tf.uint8)\n",
    "    converted_to_png = tf.image.encode_png(casted_to_uint8)\n",
    "    f = open(name, \"wb+\")\n",
    "    f.write(converted_to_png.eval())\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A class to define all args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        '''directory to store checkpointed models'''\n",
    "        self.save_dir = 'save_face_training_v0.3'\n",
    "        \n",
    "        '''Picture size'''\n",
    "        self.picture_size = 32\n",
    "    \n",
    "        '''size of RNN hidden state'''\n",
    "        self.rnn_size = self.picture_size*3 \n",
    "        '''minibatch size'''\n",
    "        self.batch_size = 1\n",
    "        '''RNN sequence length'''\n",
    "        self.seq_length = self.picture_size\n",
    "        '''number of epochs'''\n",
    "        self.num_epochs = 10 # was 5\n",
    "        '''save frequency'''\n",
    "        self.save_every = 100 # was 500\n",
    "        '''Print frequency'''\n",
    "        self.print_every = 10\n",
    "        '''clip gradients at this value'''\n",
    "        self.grad_clip = 5.\n",
    "        '''learning rate'''\n",
    "        self.learning_rate = 0.002 # was 0.002\n",
    "        '''decay rate for rmsprop'''\n",
    "        self.decay_rate = 0.98\n",
    "        \"\"\"continue training from saved model at this path.\n",
    "        Path must contain files saved by previous training process: \"\"\"\n",
    "        #self.init_from = 'save_face_training'\n",
    "        self.init_from = None\n",
    "        \n",
    "        '''number of ligne to sample'''\n",
    "        self.n = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FaceLoader:\n",
    "    def prepare_reading_faces(self):\n",
    "        self.matches = []\n",
    "    \n",
    "        for root, dirnames, filenames in os.walk('./lfw/'):\n",
    "            #print filenames\n",
    "            for filename in fnmatch.filter(filenames, '*.jpg'):\n",
    "                self.matches.append(os.path.join(root, filename))\n",
    "\n",
    "        size = len(self.matches)\n",
    "\n",
    "        filenames = tf.constant(self.matches)\n",
    "        self.filename_queue = tf.train.string_input_producer(filenames)\n",
    "        self.image_reader = tf.WholeFileReader()\n",
    "        return size\n",
    "    \n",
    "    def do_when_session(self):   \n",
    "        # For some reason, we need a coordinator and some threads\n",
    "        self.coord = tf.train.Coordinator()\n",
    "        self.threads = tf.train.start_queue_runners(coord=self.coord)\n",
    "\n",
    "    def stop_reading_faces(self):\n",
    "        # Finish off the filename queue coordinator.\n",
    "        self.coord.request_stop()\n",
    "        self.coord.join(self.threads)\n",
    "              \n",
    "    def load_one_face(self, image_size):\n",
    "        # read and decode image, will give a uint8 with shape [250, 250, 1]\n",
    "        filename, image_file = self.image_reader.read(self.filename_queue)     \n",
    "        image = tf.image.decode_jpeg(image_file, channels=1)\n",
    "        #resize\n",
    "        image = tf.image.resize_images(image, image_size, image_size)\n",
    "\n",
    "        # remove channel dimension\n",
    "        tensor_uint8 = tf.squeeze(image, squeeze_dims=[2])\n",
    "\n",
    "        # convert to float32 and scale\n",
    "        face = tf.cast(tensor_uint8, tf.float32)/255.0\n",
    "        self.picture = tf.constant(face.eval())\n",
    "        #print self.picture\n",
    "      \n",
    "    def get_bw_picts(self, level):      \n",
    "        bw = (tf.sign(self.picture-level)+1)/2\n",
    "        #print bw.eval()\n",
    "        return bw\n",
    "            \n",
    "    def get_training_set():\n",
    "        xdata = a_vector_face.eval()\n",
    "        ydata = np.copy(xdata)\n",
    "        ydata[:-1] = xdata[1:]\n",
    "        ydata[-1] = xdata[0]\n",
    "        self.x_batches = np.squeeze(np.split(xdata, image_size, 0))\n",
    "        self.y_batches = np.squeeze(np.split(ydata, image_size, 0))\n",
    "                  \n",
    "    def next_batch(self):\n",
    "        return self.x_batches, self.y_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code to  that the formulas are working.\n",
    "It create a list of pictures  \n",
    "Useless for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntf.reset_default_graph()\\nfaceloader = FaceLoader()\\nface_count = faceloader.prepare_reading_faces()\\nwith tf.Session() as sess:\\n    tf.initialize_all_variables().run()\\n    faceloader.do_when_session()\\n    faceloader.load_one_face(250)\\n    for i in range(255/2):\\n        bw = faceloader.get_bw_picts(i*2/255.)\\n        bw = tf.expand_dims(bw, 2)\\n        write_png(bw*255., \"generated{:06}.png\".format(i))\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tf.reset_default_graph()\n",
    "faceloader = FaceLoader()\n",
    "face_count = faceloader.prepare_reading_faces()\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    faceloader.do_when_session()\n",
    "    faceloader.load_one_face(250)\n",
    "    for i in range(255/2):\n",
    "        bw = faceloader.get_bw_picts(i*2/255.)\n",
    "        bw = tf.expand_dims(bw, 2)\n",
    "        write_png(bw*255., \"generated{:06}.png\".format(i))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom PIL import Image, ImageSequence\\nimport glob, sys, os\\nos.chdir(\".\")\\nframes = []\\nfor file in glob.glob(\"gene*.png\"):\\n    print(file)\\n    im = Image.open(file)\\n    frames.append(im)\\n\\nfrom images2gif import writeGif\\nwriteGif(\"generated.gif\", frames, duration=0.1)\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from PIL import Image, ImageSequence\n",
    "import glob, sys, os\n",
    "os.chdir(\".\")\n",
    "frames = []\n",
    "for file in glob.glob(\"gene*.png\"):\n",
    "    print(file)\n",
    "    im = Image.open(file)\n",
    "    frames.append(im)\n",
    "\n",
    "from images2gif import writeGif\n",
    "writeGif(\"generated.gif\", frames, duration=0.1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, args, infer=False):\n",
    "        self.args = args\n",
    "        #if infer:\n",
    "        #    '''Infer is true when the model is used for sampling'''\n",
    "        #    args.seq_length = 1\n",
    "   \n",
    "        hidden_size = args.rnn_size\n",
    "        vector_size = args.picture_size\n",
    "        \n",
    "        # define place holder to for the input data and the target.\n",
    "        self.input_data = tf.placeholder(tf.float32, [ args.seq_length, vector_size], name='input_data')\n",
    "        self.target_data = tf.placeholder(tf.float32, [ args.seq_length, vector_size], name='target_data') \n",
    "        # define the input xs\n",
    "        xs = tf.split(0, args.seq_length, self.input_data)\n",
    "        # define the target\n",
    "        targets = tf.split(0, args.seq_length, self.target_data)  \n",
    "        #initial_state\n",
    "        self.initial_state = tf.zeros((hidden_size,1))\n",
    "        #last_state = tf.placeholder(tf.float32, (hidden_size, 1))\n",
    "        \n",
    "        # model parameters\n",
    "        Wxh = tf.Variable(tf.random_uniform((hidden_size, vector_size))*0.01, name='Wxh') # input to hidden\n",
    "        Wph = tf.Variable(tf.random_uniform((hidden_size, vector_size))*0.01, name='Wph') # position to hidden\n",
    "        Whh = tf.Variable(tf.random_uniform((hidden_size, hidden_size))*0.01, name='Whh') # hidden to hidden\n",
    "        Why = tf.Variable(tf.random_uniform((vector_size, hidden_size))*0.01, name='Why') # hidden to output\n",
    "        bh = tf.Variable(tf.zeros((hidden_size, 1)), name='bh') # hidden bias\n",
    "        by = tf.Variable(tf.zeros((vector_size, 1)), name='by') # output bias\n",
    "        loss = tf.zeros([1], name='loss')\n",
    "        self.pos = tf.Variable(0.0, trainable=False, name='pos')\n",
    "        hs, ys, ps = {}, {}, {}\n",
    "        \n",
    "        hs[-1] = self.initial_state\n",
    "        # forward pass                                                                                                                                                                              \n",
    "        for t in xrange(args.seq_length):\n",
    "            xs_t = tf.transpose(xs[t])\n",
    "            if infer and t>0:\n",
    "                xs_t = ys[t-1]\n",
    "            targets_t = tf.transpose(targets[t])\n",
    "            indices = [[t, 0]]\n",
    "            values = [1.0]\n",
    "            shape = [args.seq_length, 1]\n",
    "            delta = tf.SparseTensor(indices, values, shape) \n",
    "            position = tf.zeros([vector_size, 1]) + tf.sparse_tensor_to_dense(delta)\n",
    "            \n",
    "            hs[t] = tf.sigmoid(tf.matmul(Wxh, xs_t) \n",
    "                               + tf.matmul(Whh, hs[t-1]) \n",
    "                               + tf.matmul(Wph, position)\n",
    "                               + bh) # hidden state\n",
    "            ys[t] = tf.matmul(Why, hs[t]) + by # unnormalized log probabilities for next line\n",
    "            ys[t] = tf.sigmoid(ys[t])\n",
    "            #ps[t] = tf.exp(ys[t]) / tf.reduce_sum(tf.exp(ys[t])) # probabilities for next chars\n",
    "            loss += tf.reduce_sum(tf.abs(ys[t]-targets_t))\n",
    "                \n",
    "\n",
    "        self.probs = tf.pack([ys[key] for key in ys])\n",
    "        self.cost = loss / args.batch_size / args.seq_length\n",
    "        self.final_state = hs[args.seq_length-1]\n",
    "        self.lr = tf.Variable(0.0, trainable=False, name='learning_rate')\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars),\n",
    "                args.grad_clip)\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "    def sample(self, sess):\n",
    "        size = self.args.picture_size\n",
    "        picture_vect = np.zeros((size, size))\n",
    "        state = model.initial_state.eval()\n",
    "        x = np.random.random([1, size])\n",
    "        feed = {self.input_data: x, self.initial_state:state}\n",
    "        [probs, state] = sess.run([self.probs, self.final_state], feed)\n",
    "        for n in range(0):\n",
    "            line = np.transpose(probs)\n",
    "            feed = {self.input_data: line, self.initial_state:state}\n",
    "            [probs, state] = sess.run([self.probs, self.final_state], feed)\n",
    "        for n in range(size):\n",
    "            line = np.transpose(probs)\n",
    "            feed = {self.input_data: line, self.initial_state:state}\n",
    "            [probs, state] = sess.run([self.probs, self.final_state], feed)\n",
    "            #print probs\n",
    "            #line = (np.sign(probs-0.5)+1)/2\n",
    "            #print line\n",
    "            picture_vect[n] = np.squeeze(line)  \n",
    "            picture = picture_vect*255\n",
    "        return tf.expand_dims(picture,2)\n",
    "    \n",
    "    def inspect(self, draw=False):\n",
    "        for var in tf.all_variables():\n",
    "            if var in tf.trainable_variables():\n",
    "                print ('t', var.name, var.eval().shape)\n",
    "                if draw:\n",
    "                    plt.figure(figsize=(1,1))\n",
    "                    plt.figimage(var.eval())\n",
    "                    plt.show()\n",
    "            else:\n",
    "                print ('nt', var.name, var.eval().shape)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created\n",
      "('faces count', 13233)\n",
      "variable initialized\n",
      "0/132330 (epoch 0), train_loss = 11.846004, time/batch = 0.299\n",
      "model saved to save_face_training/model.ckpt\n",
      "10/132330 (epoch 0), train_loss = 7.609998, time/batch = 0.150\n",
      "20/132330 (epoch 0), train_loss = 7.214982, time/batch = 0.150\n",
      "30/132330 (epoch 0), train_loss = 4.345308, time/batch = 0.148\n",
      "40/132330 (epoch 0), train_loss = 7.447813, time/batch = 0.154\n",
      "50/132330 (epoch 0), train_loss = 7.482661, time/batch = 0.154\n",
      "60/132330 (epoch 0), train_loss = 6.279762, time/batch = 0.153\n",
      "70/132330 (epoch 0), train_loss = 7.785715, time/batch = 0.156\n",
      "80/132330 (epoch 0), train_loss = 4.964209, time/batch = 0.161\n",
      "90/132330 (epoch 0), train_loss = 7.774941, time/batch = 0.163\n",
      "100/132330 (epoch 0), train_loss = 10.457413, time/batch = 0.162\n",
      "model saved to save_face_training/model.ckpt\n",
      "110/132330 (epoch 0), train_loss = 7.914732, time/batch = 0.165\n",
      "120/132330 (epoch 0), train_loss = 7.111222, time/batch = 0.167\n",
      "130/132330 (epoch 0), train_loss = 7.023408, time/batch = 0.168\n",
      "140/132330 (epoch 0), train_loss = 4.848790, time/batch = 0.169\n",
      "150/132330 (epoch 0), train_loss = 7.302919, time/batch = 0.171\n",
      "160/132330 (epoch 0), train_loss = 3.674625, time/batch = 0.174\n",
      "170/132330 (epoch 0), train_loss = 8.263390, time/batch = 0.176\n",
      "180/132330 (epoch 0), train_loss = 6.758085, time/batch = 0.182\n",
      "190/132330 (epoch 0), train_loss = 3.910988, time/batch = 0.179\n",
      "200/132330 (epoch 0), train_loss = 5.194339, time/batch = 0.180\n",
      "model saved to save_face_training/model.ckpt\n",
      "210/132330 (epoch 0), train_loss = 4.551933, time/batch = 0.183\n",
      "220/132330 (epoch 0), train_loss = 6.324289, time/batch = 0.190\n",
      "230/132330 (epoch 0), train_loss = 5.959601, time/batch = 0.186\n",
      "240/132330 (epoch 0), train_loss = 7.450030, time/batch = 0.188\n",
      "250/132330 (epoch 0), train_loss = 5.124949, time/batch = 0.195\n",
      "260/132330 (epoch 0), train_loss = 4.154919, time/batch = 0.200\n",
      "270/132330 (epoch 0), train_loss = 4.003494, time/batch = 0.196\n",
      "280/132330 (epoch 0), train_loss = 5.118635, time/batch = 0.205\n",
      "290/132330 (epoch 0), train_loss = 4.427326, time/batch = 0.205\n",
      "300/132330 (epoch 0), train_loss = 4.765638, time/batch = 0.208\n",
      "model saved to save_face_training/model.ckpt\n",
      "310/132330 (epoch 0), train_loss = 3.735344, time/batch = 0.211\n",
      "320/132330 (epoch 0), train_loss = 4.571231, time/batch = 0.206\n",
      "330/132330 (epoch 0), train_loss = 5.801054, time/batch = 0.207\n",
      "340/132330 (epoch 0), train_loss = 5.453507, time/batch = 0.210\n",
      "350/132330 (epoch 0), train_loss = 6.524479, time/batch = 0.214\n",
      "360/132330 (epoch 0), train_loss = 4.466758, time/batch = 0.218\n",
      "370/132330 (epoch 0), train_loss = 3.093597, time/batch = 0.215\n",
      "380/132330 (epoch 0), train_loss = 6.006961, time/batch = 0.220\n",
      "390/132330 (epoch 0), train_loss = 5.414852, time/batch = 0.221\n",
      "400/132330 (epoch 0), train_loss = 7.497438, time/batch = 0.225\n",
      "model saved to save_face_training/model.ckpt\n",
      "410/132330 (epoch 0), train_loss = 6.339993, time/batch = 0.224\n",
      "420/132330 (epoch 0), train_loss = 6.619037, time/batch = 0.230\n",
      "430/132330 (epoch 0), train_loss = 5.751145, time/batch = 0.228\n",
      "440/132330 (epoch 0), train_loss = 5.581079, time/batch = 0.231\n",
      "450/132330 (epoch 0), train_loss = 11.383739, time/batch = 0.233\n",
      "460/132330 (epoch 0), train_loss = 5.102082, time/batch = 0.233\n",
      "470/132330 (epoch 0), train_loss = 4.909813, time/batch = 0.243\n",
      "480/132330 (epoch 0), train_loss = 7.428552, time/batch = 0.245\n",
      "490/132330 (epoch 0), train_loss = 6.681951, time/batch = 0.240\n",
      "500/132330 (epoch 0), train_loss = 5.431161, time/batch = 0.245\n",
      "model saved to save_face_training/model.ckpt\n",
      "510/132330 (epoch 0), train_loss = 6.323401, time/batch = 0.248\n",
      "520/132330 (epoch 0), train_loss = 6.324689, time/batch = 0.255\n",
      "530/132330 (epoch 0), train_loss = 5.522001, time/batch = 0.254\n",
      "540/132330 (epoch 0), train_loss = 4.788240, time/batch = 0.255\n",
      "550/132330 (epoch 0), train_loss = 5.925033, time/batch = 0.259\n",
      "560/132330 (epoch 0), train_loss = 7.541386, time/batch = 0.259\n",
      "570/132330 (epoch 0), train_loss = 4.742616, time/batch = 0.270\n",
      "580/132330 (epoch 0), train_loss = 3.831331, time/batch = 0.262\n",
      "590/132330 (epoch 0), train_loss = 8.389158, time/batch = 0.278\n",
      "600/132330 (epoch 0), train_loss = 6.273591, time/batch = 0.268\n",
      "model saved to save_face_training/model.ckpt\n",
      "610/132330 (epoch 0), train_loss = 5.904160, time/batch = 0.270\n",
      "620/132330 (epoch 0), train_loss = 7.140617, time/batch = 0.268\n",
      "630/132330 (epoch 0), train_loss = 5.809810, time/batch = 0.267\n",
      "640/132330 (epoch 0), train_loss = 5.787280, time/batch = 0.272\n",
      "650/132330 (epoch 0), train_loss = 8.121449, time/batch = 0.278\n",
      "660/132330 (epoch 0), train_loss = 3.951409, time/batch = 0.281\n",
      "670/132330 (epoch 0), train_loss = 5.007551, time/batch = 0.280\n",
      "680/132330 (epoch 0), train_loss = 5.078654, time/batch = 0.277\n",
      "690/132330 (epoch 0), train_loss = 4.589311, time/batch = 0.291\n",
      "700/132330 (epoch 0), train_loss = 4.262353, time/batch = 0.295\n",
      "model saved to save_face_training/model.ckpt\n",
      "710/132330 (epoch 0), train_loss = 4.878027, time/batch = 0.284\n",
      "720/132330 (epoch 0), train_loss = 5.099174, time/batch = 0.287\n",
      "730/132330 (epoch 0), train_loss = 8.126123, time/batch = 0.292\n",
      "740/132330 (epoch 0), train_loss = 4.916740, time/batch = 0.291\n",
      "750/132330 (epoch 0), train_loss = 4.964235, time/batch = 0.293\n",
      "760/132330 (epoch 0), train_loss = 5.020784, time/batch = 0.297\n",
      "770/132330 (epoch 0), train_loss = 5.582267, time/batch = 0.301\n",
      "780/132330 (epoch 0), train_loss = 3.607513, time/batch = 0.298\n",
      "790/132330 (epoch 0), train_loss = 4.957433, time/batch = 0.304\n",
      "800/132330 (epoch 0), train_loss = 8.756006, time/batch = 0.303\n",
      "model saved to save_face_training/model.ckpt\n",
      "810/132330 (epoch 0), train_loss = 5.832938, time/batch = 0.314\n",
      "820/132330 (epoch 0), train_loss = 7.171200, time/batch = 0.310\n",
      "830/132330 (epoch 0), train_loss = 5.898413, time/batch = 0.322\n",
      "840/132330 (epoch 0), train_loss = 4.798182, time/batch = 0.318\n",
      "850/132330 (epoch 0), train_loss = 3.033494, time/batch = 0.326\n",
      "860/132330 (epoch 0), train_loss = 4.715693, time/batch = 0.323\n",
      "870/132330 (epoch 0), train_loss = 4.410551, time/batch = 0.449\n",
      "880/132330 (epoch 0), train_loss = 3.671957, time/batch = 0.340\n",
      "890/132330 (epoch 0), train_loss = 3.211787, time/batch = 0.410\n",
      "900/132330 (epoch 0), train_loss = 5.762773, time/batch = 0.347\n",
      "model saved to save_face_training/model.ckpt\n",
      "910/132330 (epoch 0), train_loss = 6.225863, time/batch = 0.348\n",
      "920/132330 (epoch 0), train_loss = 6.778830, time/batch = 0.416\n",
      "930/132330 (epoch 0), train_loss = 4.799048, time/batch = 0.447\n",
      "940/132330 (epoch 0), train_loss = 4.508432, time/batch = 0.343\n",
      "950/132330 (epoch 0), train_loss = 6.060311, time/batch = 0.364\n",
      "960/132330 (epoch 0), train_loss = 5.704145, time/batch = 0.363\n",
      "970/132330 (epoch 0), train_loss = 6.299800, time/batch = 0.376\n",
      "980/132330 (epoch 0), train_loss = 4.064652, time/batch = 0.376\n",
      "990/132330 (epoch 0), train_loss = 5.421255, time/batch = 0.351\n",
      "1000/132330 (epoch 0), train_loss = 3.249725, time/batch = 0.374\n",
      "model saved to save_face_training/model.ckpt\n",
      "1010/132330 (epoch 0), train_loss = 5.766055, time/batch = 0.370\n",
      "1020/132330 (epoch 0), train_loss = 8.624304, time/batch = 0.368\n",
      "1030/132330 (epoch 0), train_loss = 3.750180, time/batch = 0.365\n",
      "1040/132330 (epoch 0), train_loss = 5.541049, time/batch = 0.368\n",
      "1050/132330 (epoch 0), train_loss = 5.823425, time/batch = 0.366\n",
      "1060/132330 (epoch 0), train_loss = 3.467629, time/batch = 0.382\n",
      "1070/132330 (epoch 0), train_loss = 4.423463, time/batch = 0.396\n",
      "1080/132330 (epoch 0), train_loss = 7.298230, time/batch = 0.418\n",
      "1090/132330 (epoch 0), train_loss = 6.507596, time/batch = 0.405\n",
      "1100/132330 (epoch 0), train_loss = 4.531975, time/batch = 0.421\n",
      "model saved to save_face_training/model.ckpt\n",
      "1110/132330 (epoch 0), train_loss = 3.758112, time/batch = 0.430\n",
      "1120/132330 (epoch 0), train_loss = 3.868862, time/batch = 0.475\n",
      "1130/132330 (epoch 0), train_loss = 7.370373, time/batch = 0.409\n",
      "1140/132330 (epoch 0), train_loss = 4.399141, time/batch = 0.415\n",
      "1150/132330 (epoch 0), train_loss = 4.341646, time/batch = 0.395\n",
      "1160/132330 (epoch 0), train_loss = 4.806339, time/batch = 0.402\n",
      "1170/132330 (epoch 0), train_loss = 4.351828, time/batch = 0.431\n",
      "1180/132330 (epoch 0), train_loss = 3.155379, time/batch = 0.403\n",
      "1190/132330 (epoch 0), train_loss = 5.923162, time/batch = 0.412\n",
      "1200/132330 (epoch 0), train_loss = 3.506185, time/batch = 0.429\n",
      "model saved to save_face_training/model.ckpt\n",
      "1210/132330 (epoch 0), train_loss = 4.326102, time/batch = 0.413\n",
      "1220/132330 (epoch 0), train_loss = 5.531622, time/batch = 0.421\n",
      "1230/132330 (epoch 0), train_loss = 7.466490, time/batch = 0.407\n",
      "1240/132330 (epoch 0), train_loss = 5.292984, time/batch = 0.434\n",
      "1250/132330 (epoch 0), train_loss = 9.296682, time/batch = 0.442\n",
      "1260/132330 (epoch 0), train_loss = 7.542732, time/batch = 0.463\n",
      "1270/132330 (epoch 0), train_loss = 5.754212, time/batch = 0.416\n",
      "1280/132330 (epoch 0), train_loss = 6.197461, time/batch = 0.441\n",
      "1290/132330 (epoch 0), train_loss = 4.116388, time/batch = 0.452\n",
      "1300/132330 (epoch 0), train_loss = 6.148061, time/batch = 0.456\n",
      "model saved to save_face_training/model.ckpt\n",
      "1310/132330 (epoch 0), train_loss = 4.099864, time/batch = 0.446\n",
      "1320/132330 (epoch 0), train_loss = 4.672244, time/batch = 0.461\n",
      "1330/132330 (epoch 0), train_loss = 4.554517, time/batch = 0.463\n",
      "1340/132330 (epoch 0), train_loss = 4.426936, time/batch = 0.456\n",
      "1350/132330 (epoch 0), train_loss = 8.222431, time/batch = 0.448\n",
      "1360/132330 (epoch 0), train_loss = 2.372349, time/batch = 0.474\n",
      "1370/132330 (epoch 0), train_loss = 4.806358, time/batch = 0.453\n",
      "1380/132330 (epoch 0), train_loss = 2.799022, time/batch = 0.478\n",
      "1390/132330 (epoch 0), train_loss = 3.600282, time/batch = 0.461\n",
      "1400/132330 (epoch 0), train_loss = 5.314572, time/batch = 0.487\n",
      "model saved to save_face_training/model.ckpt\n",
      "1410/132330 (epoch 0), train_loss = 3.716839, time/batch = 0.474\n",
      "1420/132330 (epoch 0), train_loss = 5.867580, time/batch = 0.502\n",
      "1430/132330 (epoch 0), train_loss = 3.307088, time/batch = 0.483\n",
      "1440/132330 (epoch 0), train_loss = 5.661429, time/batch = 0.524\n",
      "1450/132330 (epoch 0), train_loss = 5.752923, time/batch = 0.488\n",
      "1460/132330 (epoch 0), train_loss = 5.262812, time/batch = 0.516\n",
      "1470/132330 (epoch 0), train_loss = 4.028398, time/batch = 0.525\n",
      "1480/132330 (epoch 0), train_loss = 3.386873, time/batch = 0.508\n",
      "1490/132330 (epoch 0), train_loss = 7.146141, time/batch = 0.537\n",
      "1500/132330 (epoch 0), train_loss = 2.592293, time/batch = 0.503\n",
      "model saved to save_face_training/model.ckpt\n",
      "1510/132330 (epoch 0), train_loss = 4.420721, time/batch = 0.540\n",
      "1520/132330 (epoch 0), train_loss = 6.661725, time/batch = 0.538\n",
      "1530/132330 (epoch 0), train_loss = 3.700504, time/batch = 0.534\n",
      "1540/132330 (epoch 0), train_loss = 6.506403, time/batch = 0.519\n",
      "1550/132330 (epoch 0), train_loss = 4.536848, time/batch = 0.544\n",
      "1560/132330 (epoch 0), train_loss = 5.640853, time/batch = 0.551\n",
      "1570/132330 (epoch 0), train_loss = 5.638056, time/batch = 0.520\n",
      "1580/132330 (epoch 0), train_loss = 7.173485, time/batch = 0.541\n",
      "1590/132330 (epoch 0), train_loss = 2.604686, time/batch = 0.538\n",
      "1600/132330 (epoch 0), train_loss = 3.820972, time/batch = 0.534\n",
      "model saved to save_face_training/model.ckpt\n",
      "1610/132330 (epoch 0), train_loss = 3.754754, time/batch = 0.554\n",
      "1620/132330 (epoch 0), train_loss = 2.470329, time/batch = 0.541\n",
      "1630/132330 (epoch 0), train_loss = 5.454981, time/batch = 0.544\n",
      "1640/132330 (epoch 0), train_loss = 3.191897, time/batch = 0.556\n",
      "1650/132330 (epoch 0), train_loss = 3.515225, time/batch = 0.558\n",
      "1660/132330 (epoch 0), train_loss = 2.818658, time/batch = 0.554\n",
      "1670/132330 (epoch 0), train_loss = 3.251315, time/batch = 0.559\n",
      "1680/132330 (epoch 0), train_loss = 4.379750, time/batch = 0.575\n",
      "1690/132330 (epoch 0), train_loss = 6.107162, time/batch = 0.581\n",
      "1700/132330 (epoch 0), train_loss = 10.520744, time/batch = 0.573\n",
      "model saved to save_face_training/model.ckpt\n",
      "1710/132330 (epoch 0), train_loss = 5.984098, time/batch = 0.576\n",
      "1720/132330 (epoch 0), train_loss = 3.026716, time/batch = 0.578\n",
      "1730/132330 (epoch 0), train_loss = 5.400842, time/batch = 0.577\n",
      "1740/132330 (epoch 0), train_loss = 4.510511, time/batch = 0.601\n",
      "1750/132330 (epoch 0), train_loss = 5.325934, time/batch = 0.585\n",
      "1760/132330 (epoch 0), train_loss = 5.739883, time/batch = 0.597\n",
      "1770/132330 (epoch 0), train_loss = 2.015807, time/batch = 0.606\n",
      "1780/132330 (epoch 0), train_loss = 2.713206, time/batch = 0.585\n",
      "1790/132330 (epoch 0), train_loss = 5.520914, time/batch = 0.639\n",
      "1800/132330 (epoch 0), train_loss = 2.586047, time/batch = 0.644\n",
      "model saved to save_face_training/model.ckpt\n",
      "1810/132330 (epoch 0), train_loss = 5.679832, time/batch = 0.645\n",
      "1820/132330 (epoch 0), train_loss = 3.191137, time/batch = 0.657\n",
      "1830/132330 (epoch 0), train_loss = 3.479776, time/batch = 0.647\n",
      "1840/132330 (epoch 0), train_loss = 6.601597, time/batch = 0.668\n",
      "1850/132330 (epoch 0), train_loss = 3.503648, time/batch = 0.658\n",
      "1860/132330 (epoch 0), train_loss = 3.836609, time/batch = 0.663\n",
      "1870/132330 (epoch 0), train_loss = 3.950723, time/batch = 0.663\n",
      "1880/132330 (epoch 0), train_loss = 5.474760, time/batch = 0.691\n",
      "1890/132330 (epoch 0), train_loss = 4.600953, time/batch = 0.659\n",
      "1900/132330 (epoch 0), train_loss = 5.153743, time/batch = 0.668\n",
      "model saved to save_face_training/model.ckpt\n",
      "1910/132330 (epoch 0), train_loss = 4.155967, time/batch = 0.638\n",
      "1920/132330 (epoch 0), train_loss = 3.450524, time/batch = 0.714\n",
      "1930/132330 (epoch 0), train_loss = 3.735923, time/batch = 0.656\n",
      "1940/132330 (epoch 0), train_loss = 3.744927, time/batch = 0.642\n",
      "1950/132330 (epoch 0), train_loss = 3.671499, time/batch = 0.744\n",
      "1960/132330 (epoch 0), train_loss = 3.720388, time/batch = 0.656\n",
      "1970/132330 (epoch 0), train_loss = 5.815224, time/batch = 0.670\n",
      "1980/132330 (epoch 0), train_loss = 3.059415, time/batch = 0.672\n",
      "1990/132330 (epoch 0), train_loss = 3.465191, time/batch = 0.677\n",
      "2000/132330 (epoch 0), train_loss = 2.620191, time/batch = 0.690\n",
      "model saved to save_face_training/model.ckpt\n",
      "2010/132330 (epoch 0), train_loss = 4.495060, time/batch = 0.685\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "args = Args()\n",
    "model = Model(args)\n",
    "print (\"model created\")\n",
    "faceloader = FaceLoader()\n",
    "face_count = faceloader.prepare_reading_faces()\n",
    "print ('faces count', face_count)\n",
    "\n",
    "cost_optimisation = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print (\"variable initialized\")\n",
    "    faceloader.do_when_session()\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "    # restore model\n",
    "    if args.init_from is not None:\n",
    "        ckpt = tf.train.get_checkpoint_state(args.init_from)\n",
    "        assert ckpt,\"No checkpoint found\"\n",
    "        assert ckpt.model_checkpoint_path,\"No model path found in checkpoint\"\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print (\"model restored\")\n",
    "    for e in range(args.num_epochs):\n",
    "        faceloader.image_reader.reset()\n",
    "        sess.run(tf.assign(model.lr, args.learning_rate * (args.decay_rate ** e)))\n",
    "        state = model.initial_state.eval()\n",
    "        for b in range(face_count):\n",
    "            start = time.time()\n",
    "            # Get learning data\n",
    "            faceloader.load_one_face(args.picture_size)\n",
    "            x, y = faceloader.next_batch()\n",
    "            # Create the structure for the learning data\n",
    "            feed = {model.input_data: x, model.target_data: y, model.initial_state: state}\n",
    "            # Run a session using train_op\n",
    "            [train_loss], state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\n",
    "            end = time.time()\n",
    "            if (e * face_count + b) % args.print_every == 0:\n",
    "                cost_optimisation.append(train_loss)\n",
    "                print(\"{}/{} (epoch {}), train_loss = {:.6f}, time/batch = {:.3f}\" \\\n",
    "                    .format(e * face_count + b,\n",
    "                            args.num_epochs * face_count,\n",
    "                            e, train_loss, end - start))\n",
    "            if (e * face_count + b) % args.save_every == 0:\n",
    "                checkpoint_path = os.path.join(args.save_dir, 'model.ckpt')\n",
    "                saver.save(sess, checkpoint_path, global_step = e * face_count + b)\n",
    "                print(\"model saved to {}\".format(checkpoint_path))\n",
    "                np.save('cost', cost_optimisation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost_optimisation = np.load('cost.npy')\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(range(len(cost_optimisation)), cost_optimisation, label='cost')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "args = Args()\n",
    "model = Model(args, True)  # True to generate the model in sampling mode\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "    ckpt = tf.train.get_checkpoint_state(args.save_dir)\n",
    "    print (ckpt)\n",
    "    \n",
    "    model.inspect(draw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intialisation done\n",
      "model_checkpoint_path: \"save_face_training/model.ckpt-2000\"\n",
      "all_model_checkpoint_paths: \"save_face_training/model.ckpt-1600\"\n",
      "all_model_checkpoint_paths: \"save_face_training/model.ckpt-1700\"\n",
      "all_model_checkpoint_paths: \"save_face_training/model.ckpt-1800\"\n",
      "all_model_checkpoint_paths: \"save_face_training/model.ckpt-1900\"\n",
      "all_model_checkpoint_paths: \"save_face_training/model.ckpt-2000\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "args = Args()\n",
    "model = Model(args, infer=True)\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print 'intialisation done'\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "    ckpt = tf.train.get_checkpoint_state(args.save_dir)\n",
    "    print (ckpt)\n",
    "    \n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "               \n",
    "    state = model.initial_state.eval()\n",
    "    x = np.random.random([args.picture_size, args.picture_size])\n",
    "    feed = {model.input_data: x, model.initial_state: state}\n",
    "    [lines] = sess.run([model.probs], feed)\n",
    "    pict = tf.expand_dims(lines*255,2)\n",
    "    #print(pict.eval())\n",
    "    write_png(lines*255, 'a_face.png')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAB6klEQVQ4jW1SQbLbOgwDQDpOMtMb\n/0v+s3Ta1I4IdOG8ThfVSsSAEgCS/z3urWSt1zv3cj2Ogc9Dt6I8nN7veyuWViKKqoAbtr0pm9Nb\nbyULkcYwPEOi+rZJNldXSWIsxpPJmiHDqi7ZZFdVyRHg92C6zkVBkFQy0FUtMSN4MXafQ7ETkCHd\nFElCBJIM7SGYAAADtsdAEtT2EFzPc1FWEYkT91GsSlZ033dZz3Mx71XIxMb02awKxqh+tPXYFn28\nmGHGmZ5VQGIbkCBJBJkE9mB6ZhjEscg/BAAIEqRvt1spWGuO169yPY8h3nNTSR5U3++75MA5z5+c\nfl1BNarKBfVaVUnAvu83TT3PRc705RPug2khtvbt2dbjHPr4VbA1k9W2B5di2YZtxnHCJEhXt8pw\n1pyrpt7HIte6BVQACwBBIFfgCIBcRZCgJZGACGfZfr8XOQYkIVBfPQBIllhVIQPyQtF2ksQJ8VeS\nF2i6cX2XeLDirLXIubqAS0MxIfyeJTfORZkdkCTVkiiDiFdob+dQ0UcV2V/WvgDKBGGbvDTkkxlI\nEbo4QBI7uN66pv/v0yBIgiSBrwuBqwJakqjos/cfdxcDJFsqyREJE0Pb0EcVAPb/2yNY83p9//GD\n4PaYN3S7f3vutXm29RsylZQD43DXWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(\"a_face.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback wellcome __@dh7net__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
