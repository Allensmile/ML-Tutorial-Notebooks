{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# A Word2Vec playground\n",
    "\n",
    "To play with this notebook, you'll need Numpy, Annoy, Gensim, and the [GoogleNews word2vec model]( https://code.google.com/archive/p/word2vec/)\n",
    "\n",
    "* pip install numpy\n",
    "* pip install annoy  \n",
    "* pip install gensim  \n",
    "* you can find the GoogleNews vector by googling _./GoogleNews-vectors-negative300.bin_  \n",
    "  \n",
    "\n",
    "Inspired by: https://github.com/chrisjmccormick/inspect_word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import and init\n",
    "from annoy import AnnoyIndex\n",
    "import gensim\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "prefix_filename = 'word2vec'\n",
    "ann_filename = prefix_filename + '.ann'\n",
    "i2k_filename = prefix_filename + '_i2k.npy'\n",
    "k2i_filename = prefix_filename + '_k2i.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create a model or load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load GoogleNews Model\n",
      "loading done\n",
      "model size= 3000000\n",
      "vector size= 300\n"
     ]
    }
   ],
   "source": [
    "# Load Google's pre-trained Word2Vec model.\n",
    "print \"load GoogleNews Model\"\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "print \"loading done\"\n",
    "\n",
    "hello = model['hello']\n",
    "vector_size = len(hello)\n",
    "print 'model size=', len(model.vocab)\n",
    "print 'vector size=', vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating indexes\n",
      "10000 DeLille_Cellars\n",
      "20000 igned\n",
      "30000 industrial_Ruhr\n",
      "40000 ANSI_ASHRAE_IESNA_Standard\n",
      "50000 coach_Jay_Vidovich\n",
      "60000 Kizil\n",
      "70000 Nanakshahi\n",
      "80000 iSink_U_Facebook\n",
      "90000 Renfrey\n",
      "100000 Doctorate_Degree\n",
      "110000 Synthetic_Cannabinoids\n",
      "120000 Employee_Jeff_Colucy\n",
      "130000 Kolbek\n",
      "140000 dunce_hat\n",
      "150000 Irn_Bru_First\n",
      "160000 model_Maggie_Rizer\n",
      "170000 OTTAWA_Karlheinz_Schreiber\n",
      "180000 BGiles\n",
      "190000 prMac.com_Vienna_Austria\n",
      "200000 Tina_Pisnik\n",
      "210000 undersigned_Rubin_Lublin\n",
      "220000 Willnett_Crockett\n",
      "230000 Sony_Pictures_Studios\n",
      "240000 Voices\n",
      "250000 salmon_Delta_smelt\n",
      "260000 Yasuaki_Iwamoto_auto\n",
      "270000 Ambrose\n",
      "280000 DeLamatre\n",
      "290000 BY_JOYCE_J._PERSICO\n",
      "300000 Austin_Ruse\n",
      "310000 Adeline_Teoh\n",
      "320000 1_Utama_Shopping\n",
      "330000 iSimCity\n",
      "340000 symbol_TOT.UN\n",
      "350000 southeastwards\n",
      "360000 Whitchurch_Heath\n",
      "370000 WEXFORD\n",
      "380000 Kirk_Baert\n",
      "390000 church_renounced_polygamy\n",
      "400000 Whitney_Otis_elevators\n",
      "410000 Fonze\n",
      "420000 Fabian_Babich\n",
      "430000 Desmodur_®\n",
      "440000 Michael_Egholm_Ph.D.\n",
      "450000 Cookie_Zip\n",
      "460000 David_Dal_Maso\n",
      "470000 Santa_Barbara_Botanic_Garden\n",
      "480000 Jellicoe_Road\n",
      "490000 E_coli\n",
      "500000 Burleith\n",
      "510000 LSBK\n",
      "520000 Maidie\n",
      "530000 Buddha_Nallah\n",
      "540000 Coast_Guard_watchstanders\n",
      "550000 EPIRB_signal\n",
      "560000 Comtech_Telecommunications_Corp.\n",
      "570000 Silver_oz.\n",
      "580000 Dominique_Darden\n",
      "590000 Raiders_George_Blanda\n",
      "600000 attract_younger_hipper\n",
      "610000 backstabbed\n",
      "620000 Omro_Rushford_Fire\n",
      "630000 Lasse\n",
      "640000 BY_DENNIS_BARTLOW\n",
      "650000 Yorkshire_Casualty_Reduction\n",
      "660000 Korleone_Young\n",
      "670000 David_Dzhokhadze\n",
      "680000 Rudy_Currence\n",
      "690000 Archive_retrievals\n",
      "700000 Dousis\n",
      "710000 Albert_Kligman\n",
      "720000 actress_Archie_Panjabi\n",
      "730000 Wolf_Haldenstein\n",
      "740000 Lendel_Thomas\n",
      "750000 Grubka\n",
      "760000 Rene_Charlebois\n",
      "770000 arsenic\n",
      "780000 Minkus_Electronic_Display\n",
      "790000 Ibi_Kaslik\n",
      "800000 Valhall\n",
      "810000 visibly_irritated_plainclothes\n",
      "820000 Norwegian_expressionist_Edvard\n",
      "830000 troy_oz\n",
      "840000 PfEMP1\n",
      "850000 μ_velOSity\n",
      "860000 active_RFID_RTLS\n",
      "870000 Pitched_Perfectly\n",
      "880000 JRT\n",
      "890000 scotch_carts\n",
      "900000 Insurer_Humana\n",
      "910000 Monica_Isley\n",
      "920000 Julie_Deardorff\n",
      "930000 Doc_Paulin\n",
      "940000 http://www.opengeospatial.org\n",
      "950000 Microcell_Telecommunications_Inc.\n",
      "960000 PRNewswire_FirstCall_FNDS####_Corp\n",
      "970000 MENNONITE\n",
      "980000 Gabelsville\n",
      "990000 PLN_##.#mn\n",
      "1000000 Graebe\n",
      "1010000 midges_swarmed\n",
      "1020000 Gokool\n",
      "1030000 Laura_Stotler_writes\n",
      "1040000 remotely_piloted_Predators\n",
      "1050000 Antlered_deer\n",
      "1060000 desolate_desert\n",
      "1070000 DRCE\n",
      "1080000 Dhiya_al_Kenani\n",
      "1090000 Lily_Ledbetter\n",
      "1100000 Flatford\n",
      "1110000 nurdled\n",
      "1120000 Electron_Optics\n",
      "1130000 Hostos_Community_College\n",
      "1140000 NVIDIA_PhysX\n",
      "1150000 Eurythmics\n",
      "1160000 Crazed_Fan\n",
      "1170000 Tullett_Liberty\n",
      "1180000 Hunka_Hunka_Burnin\n",
      "1190000 Eat_Your_Own\n",
      "1200000 ENSOR\n",
      "1210000 nemesis_Captain_Hook\n",
      "1220000 U._Shrinivas\n",
      "1230000 penile_enlargement\n",
      "1240000 Antolin_Alcaraz\n",
      "1250000 parimutuel_betting\n",
      "1260000 Shell_Petroleum\n",
      "1270000 Woodenbong\n",
      "1280000 Kishoreganj_district\n",
      "1290000 tee'd\n",
      "1300000 Niweigha\n",
      "1310000 Engine_Overhaul\n",
      "1320000 Jen_Marlowe\n",
      "1330000 Nitsch\n",
      "1340000 Tiananmen_dissident\n",
      "1350000 expletive_laden_banter\n",
      "1360000 eurocentric\n",
      "1370000 provincial_spokesman_Zulmi\n",
      "1380000 Thurrock_Harriers\n",
      "1390000 Psychosocial_Factors\n",
      "1400000 Imagi_Mangal\n",
      "1410000 Marco_Rubio\n",
      "1420000 distinguishes\n",
      "1430000 Malaman\n",
      "1440000 bowled_Peter_Ongondo\n",
      "1450000 Patricia_A._Vinchesi\n",
      "1460000 Keltbray\n",
      "1470000 Jolliff\n",
      "1480000 SERIOUS_MAN\n",
      "1490000 Egyptians_resealed\n",
      "1500000 BROKE_INTO\n",
      "1510000 Texas_hold'em\n",
      "1520000 Caruso_Benefits\n",
      "1530000 ENTrigue_Surgical\n",
      "1540000 Southern_Tagalog_Arterial\n",
      "1550000 OHL'_murt\n",
      "1560000 DeSean_Jackson\n",
      "1570000 Adepoju\n",
      "1580000 Kachkar\n",
      "1590000 &_quotWe\n",
      "1600000 Eyewear_Collection\n",
      "1610000 novitiate\n",
      "1620000 Inferiority_Complex\n",
      "1630000 papal_nuncio_Benedict\n",
      "1640000 Lyddiard_website\n",
      "1650000 MTM###_MPEG_Transport\n",
      "1660000 gypsum_stack\n",
      "1670000 Taiwan_Straits_ARATS\n",
      "1680000 AWARD_FOR_BEST\n",
      "1690000 Elmaghraby\n",
      "1700000 fright_fests\n",
      "1710000 IMMUNE_SYSTEMS\n",
      "1720000 spokesman_Larry_Solters\n",
      "1730000 burial\n",
      "1740000 BY_RAMONA_SHELBURNE\n",
      "1750000 Maaroufi\n",
      "1760000 bin_Qasim\n",
      "1770000 assassinate_Sheik_Jaber\n",
      "1780000 Marc_Axton\n",
      "1790000 Lockerman\n",
      "1800000 Isberto\n",
      "1810000 Gatson\n",
      "1820000 Jennifer_Klinkert\n",
      "1830000 Memento_mori\n",
      "1840000 Desi_Arnez\n",
      "1850000 HEALTH_PLANS\n",
      "1860000 Finger_Lakes_Riesling\n",
      "1870000 Colonel_Mengistu_Haile_Mariam\n",
      "1880000 Hotel_Sacher\n",
      "1890000 Monticello_Ky.\n",
      "1900000 Dr._Josyann_Abisaab\n",
      "1910000 By_Lawerence_Synett\n",
      "1920000 Aprimo_Marketing_Studio\n",
      "1930000 Severe_thunderstorms\n",
      "1940000 raster_imagery\n",
      "1950000 settlement_blocs_Maaleh_Adumim\n",
      "1960000 postherpetic_neuralgia\n",
      "1970000 Dave_Betras\n",
      "1980000 HKY_FLA\n",
      "1990000 Gulbudin_Hekmatyar\n",
      "2000000 Klip_south\n",
      "2010000 crumbling_lakeside\n",
      "2020000 Philadelphia_Pa_Lippincott\n",
      "2030000 JOBE\n",
      "2040000 FABIO_Capello\n",
      "2050000 T2_weighted\n",
      "2060000 Burke_Badenhop\n",
      "2070000 Weather_Stations\n",
      "2080000 Sogluizzo\n",
      "2090000 AUTHORITY_OF\n",
      "2100000 Slim_Goodbody\n",
      "2110000 Nizam_Mir\n",
      "2120000 NewYork_Presbyterian_Hospital\n",
      "2130000 Chairman_Jimmy_Iovine\n",
      "2140000 Quail_Run_Elementary\n",
      "2150000 neckware_line\n",
      "2160000 aminopyralid\n",
      "2170000 Essex_Fells\n",
      "2180000 DOJ_OIG\n",
      "2190000 BONDING\n",
      "2200000 fking\n",
      "2210000 REALTOR_®_Lockbox_NXT\n",
      "2220000 therapeutic_compound_GAMMAGARD\n",
      "2230000 Loof\n",
      "2240000 Nomir_Medical_Technologies\n",
      "2250000 Guilia\n",
      "2260000 MetaSphere_application\n",
      "2270000 Qi_Ji\n",
      "2280000 brewers_Anheuser_Busch\n",
      "2290000 8dec\n",
      "2300000 Balachander\n",
      "2310000 Baoyu\n",
      "2320000 forwards_Colby_Armstrong\n",
      "2330000 Hanjin_Heavy_Industries\n",
      "2340000 Permanently_extending\n",
      "2350000 Mohsenian\n",
      "2360000 dark_Lord_Voldemort\n",
      "2370000 visit_http://www.elpaso.com\n",
      "2380000 CONTACT_Universal_Stainless\n",
      "2390000 Steve_Schale_Democratic\n",
      "2400000 BY_ROB_STEIN\n",
      "2410000 INTERNET_TELEPHONY_Conference\n",
      "2420000 Cloux_France\n",
      "2430000 Superwire_Inc.\n",
      "2440000 Rothiemurchus\n",
      "2450000 Menarik_Property\n",
      "2460000 TOM_MACK\n",
      "2470000 noni_juice\n",
      "2480000 Larder_Lake_Property\n",
      "2490000 confortable\n",
      "2500000 Gowad\n",
      "2510000 racewinner\n",
      "2520000 Hazard_Elimination\n",
      "2530000 wet_distiller_grains\n",
      "2540000 downtown_honky_tonks\n",
      "2550000 potency_dosing\n",
      "2560000 Lupercalia\n",
      "2570000 Niuatoputapu_wiping\n",
      "2580000 lambasted\n",
      "2590000 caisse\n",
      "2600000 evrything\n",
      "2610000 Molecular_Pharmacology_Physiology\n",
      "2620000 Bill_Kostroun_FILE\n",
      "2630000 directorial_reigns\n",
      "2640000 Calle_Ridderwall\n",
      "2650000 Schlappi\n",
      "2660000 Orin_Hatch\n",
      "2670000 cricketer_Anil_Kumble\n",
      "2680000 Yoshinori_Nagano_strategist\n",
      "2690000 Brahim_Boulami\n",
      "2700000 Klaasen\n",
      "2710000 Dovetail_Solar\n",
      "2720000 Southwark_diocese\n",
      "2730000 AND_COUPLE_DANCING\n",
      "2740000 disassociates_itself\n",
      "2750000 R._Madhavan\n",
      "2760000 Kibwezi\n",
      "2770000 KIMBERLY_EDDS\n",
      "2780000 Sunway_Lagoon_Surf\n",
      "2790000 PKR_supreme\n",
      "2800000 nonsmokers_groused\n",
      "2810000 Glyco\n",
      "2820000 IronStone\n",
      "2830000 Billings_Forge\n",
      "2840000 Famer_Gordie_Howe\n",
      "2850000 By_Eric_Mchugh\n",
      "2860000 Ingrid_Beckles\n",
      "2870000 Savory_Spice\n",
      "2880000 Jamnong\n",
      "2890000 TVonics\n",
      "2900000 MENAFN_Arab\n",
      "2910000 Imam_Khomeini_mausoleum\n",
      "2920000 Mayor_Arturo_Garino\n",
      "2930000 Dogwood_Trail\n",
      "2940000 Joel_Scodnick\n",
      "2950000 Brenner_CSO\n",
      "2960000 Brownscombe\n",
      "2970000 Ezra_Cray\n",
      "2980000 Katrina_Relief_Efforts\n",
      "2990000 EMILY_KAISER\n",
      "3000000 Kenneth_Klinge\n",
      "building 10 trees\n",
      "save files\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# process the model and save a model\n",
    "# or load the model directly\n",
    "vocab = model.vocab.keys()\n",
    "#indexNN = AnnoyIndex(vector_size, metric='angular')\n",
    "indexNN = AnnoyIndex(vector_size)\n",
    "index2key = [None]*len(model.vocab)\n",
    "key2index = {}\n",
    "\n",
    "if not os.path.isfile(ann_filename): \n",
    "    print 'creating indexes'\n",
    "    i = 0\n",
    "    try:\n",
    "        for key in vocab:\n",
    "            indexNN.add_item(i, model[key])\n",
    "            key2index[key]=i\n",
    "            index2key[i]=key\n",
    "            i=i+1\n",
    "            if (i%10000==0):\n",
    "                print i, key\n",
    "    except TypeError:\n",
    "        print 'Error with key', key\n",
    "    print 'building 10 trees'\n",
    "    indexNN.build(10) # 10 trees\n",
    "    print 'save  files'\n",
    "    indexNN.save(ann_filename)\n",
    "    np.save(i2k_filename, index2key)\n",
    "    np.save(k2i_filename, key2index)\n",
    "    print 'done'\n",
    "else:\n",
    "    print \"loading files\"\n",
    "    indexNN.load(ann_filename)\n",
    "    index2key = np.load(i2k_filename)\n",
    "    key2index = np.load(k2i_filename)\n",
    "    print \"loading done:\", indexNN.get_n_items(), \"items\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## King - Male + Female = Queen?\n",
    "Nope!\n",
    "\n",
    "At least not based on a word2vec that is trained on the News..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king\n"
     ]
    }
   ],
   "source": [
    "what_vec = model['king'] - model['male'] + model['female']\n",
    "\n",
    "what_indexes = indexNN.get_nns_by_vector(what_vec, 1)\n",
    "print index2key[what_indexes[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## King - boy + girl = Queen?\n",
    "Yes :)  \n",
    "but it don't work with man & women :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen\n"
     ]
    }
   ],
   "source": [
    "what_vec = model['king'] - model['boy'] + model['girl']\n",
    "\n",
    "what_indexes = indexNN.get_nns_by_vector(what_vec, 1)\n",
    "print index2key[what_indexes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute_monarch\n"
     ]
    }
   ],
   "source": [
    "what_vec = model['king'] - model['man'] + model['women']\n",
    "\n",
    "what_indexes = indexNN.get_nns_by_vector(what_vec, 1)\n",
    "print index2key[what_indexes[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Berlin  - Germany + France = Paris?\n",
    "Yes!\n",
    "\n",
    "This makes me happy, but if someone understand why, please tell me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris\n"
     ]
    }
   ],
   "source": [
    "what_vec = model['Berlin'] - model['Germany'] + model['France']\n",
    "\n",
    "what_indexes = indexNN.get_nns_by_vector(what_vec, 1)\n",
    "print index2key[what_indexes[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Trump - USA + Germany = Hitler?\n",
    "FAKE NEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dean_Gitter\n"
     ]
    }
   ],
   "source": [
    "what_vec = model['Trump'] + model['Germany'] - model['USA']\n",
    "what_indexes = indexNN.get_nns_by_vector(what_vec, 1)\n",
    "\n",
    "for i in what_indexes:\n",
    "    print index2key[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Let's explore the stereotypes hidded in the news:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king for him, queen for her.\n",
      "prince for him, duchess for her.\n",
      "male for him, female for her.\n",
      "boy for him, girl for her.\n",
      "dad for him, motherly_instincts for her.\n",
      "father for him, mother for her.\n",
      "president for him, president for her.\n",
      "dentist for him, plastic_surgeon for her.\n",
      "scientist for him, linguistics_professor for her.\n",
      "efficient for him, efficient for her.\n",
      "teacher for him, teacher for her.\n",
      "doctor for him, doctor for her.\n",
      "minister for him, minister for her.\n",
      "lover for him, seductress for her.\n"
     ]
    }
   ],
   "source": [
    "man2women =  - model['boy'] + model['girl'] \n",
    "\n",
    "word_list = [\"king\",\"prince\", \"male\", \"boy\",\"dad\", \"father\", \"president\", \"dentist\",\n",
    "             \"scientist\", \"efficient\",  \"teacher\", \"doctor\", \"minister\", \"lover\"]\n",
    "for word in word_list:\n",
    "    what_vec = model[word] + man2women\n",
    "    what_indexes = indexNN.get_nns_by_vector(what_vec, 1)\n",
    "    print word, \"for him,\", index2key[what_indexes[0]], \"for her.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin is the capital of Germany\n",
      "Paris is the capital of France\n",
      "Rome is the capital of Italy\n",
      "Teen_Poetry_Slam is the capital of USA\n",
      "Moscow is the capital of Russia\n",
      "kids is the capital of boys\n",
      "paddywagon is the capital of cars\n",
      "flower is the capital of flowers\n",
      "civilians is the capital of soldiers\n",
      "Humberto_Campins is the capital of scientists\n"
     ]
    }
   ],
   "source": [
    "capital = model['Berlin'] - model['Germany'] \n",
    "\n",
    "word_list = [\"Germany\", \"France\", \"Italy\", \"USA\", \"Russia\", \"boys\", \"cars\", \"flowers\", \"soldiers\",\n",
    "             \"scientists\", ]\n",
    "for word in word_list:\n",
    "    what_vec = model[word] + capital\n",
    "    what_indexes = indexNN.get_nns_by_vector(what_vec, 1)\n",
    "    print index2key[what_indexes[0]], \"is the capital of\", word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you play with this notebook and find good word2vec equation, please tweet them to me!  \n",
    "__@dh7net__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
